{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "deeplearning",
   "display_name": "(Conda) DL",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 align=\"center\">Trabalho 2 - Aprendizagem de Mﾃ｡quina</h1>\n",
    "\n",
    "## Andre Brun\n",
    "### Daniel Boll & Mateus Karvat\n",
    "---\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Inicialmente, importamos as bibliotecas necessﾃ｡rias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import style, cm\n",
    "import matplotlib.tri as mtri\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "\n",
    "# Analitics\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Configurations\n",
    "style.use('ggplot')\n",
    "%matplotlib qt\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "source": [
    "Em seguida, carregamos a base de dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Base9.csv')\n",
    "\n",
    "# Manteremos uma cﾃｳpia dos dados originais\n",
    "# para garantia\n",
    "raw_data = data.copy()"
   ]
  },
  {
   "source": [
    "Separando as coordenadas x e y na variﾃ｡vel ***X*** e as labels na variﾃ｡vel ***label***."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.values[:, :2])\n",
    "label = np.array(data.values[:, 2])"
   ]
  },
  {
   "source": [
    "Apﾃｳs carregar a base e separﾃ｡-la, plotamos o *dataset* com as cores verde para a primeira classe e vermelha para a segunda. O dataset ﾃｩ popularmente chamado de \"Banana\", de modo que ocasionalmente nos referimos a cada cluster como uma \"banana\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"g.\", \"r.\", \"c.\", \"b.\"] ## No caso de ter atﾃｩ 4 classes\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], colors[int(label[i])])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/dataset_plot.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Metricas de avaliaﾃｧﾃ｣o \n",
    "\n",
    "Funﾃｧﾃｵes implementadas por nﾃｳs para as mﾃｩtricas de avaliaﾃｧﾃ｣o nﾃ｣o implementadas pelas bibliotecas utilizadas. A mﾃｩtrica de Silhueta ﾃｩ utilizada a partir de funﾃｧﾃ｣o prﾃｩ-pronta do SciKit Learn."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Coesﾃ｣o"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohesion_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - N dentro de uma mesma label\n",
    "    pra cada label definida pelo classificador\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "\n",
    "    # para cada label, obtemos a matriz subX, que contﾃｩm as coordenadas dos pontos daquelas labels\n",
    "    for lab in each_label:\n",
    "        if lab!=-1:\n",
    "            indices = np.where(labels == lab)\n",
    "            indices = indices[0]\n",
    "            subX = np.take(X, indices, axis=0)\n",
    "\n",
    "            # verificamos a distﾃ｢ncia euclidiana entre todos os pares de pontos em subX\n",
    "            total += np.sum(pairwise_distances(subX, metric='sqeuclidean', n_jobs=-1))\n",
    "\n",
    "    # a fim de reduzir a dimensﾃ｣o do resultado, retornarmos sua raiz quadrada\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "source": [
    "### Separaﾃｧﾃ｣o"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - M\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "    \n",
    "    # assim como na coesﾃ｣o, obtemos a matriz subX com os pontos pertencentes a uma mesma label. Porﾃｩm, aqui precisamos da matriz subY com os pontos pertencentes ﾃs demais labels.\n",
    "    for lab in each_label:\n",
    "        if lab!=-1:\n",
    "            indices_x = np.where(labels == lab)\n",
    "            indices_x = indices_x[0]\n",
    "\n",
    "            indices_y = np.where(np.logical_and(labels != lab, labels!=-1))\n",
    "            indices_y = indices_y[0]\n",
    "            \n",
    "            subX = np.take(X, indices_x, axis=0)\n",
    "            subY = np.take(X, indices_y, axis=0)\n",
    "\n",
    "            # calculamos a distﾃ｢ncia entre os pontos de subX e os pontos de subY\n",
    "            total += np.sum(pairwise_distances(subX, subY, metric='sqeuclidean', n_jobs=-1))\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "source": [
    "### Entropia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_score(X, label_class, label_dataset):\n",
    "    \"\"\"\n",
    "        banana 轟\n",
    "        B1 = label_dataset == 1\n",
    "        B2 = label_dataset == 0\n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(label_dataset)\n",
    "    total_entropy = 0\n",
    "    for label in cluster_labels:\n",
    "        cluster_entropy = 0\n",
    "        \n",
    "        # Cluster indices tem o ﾃｭndice\n",
    "        # de uma banana (dataset original)\n",
    "        cluster_indices = np.where(label_dataset == label)\n",
    "        cluster_indices = cluster_indices[0]\n",
    "\n",
    "        # Tem todas as instﾃ｢ncias da label_class\n",
    "        # dentro da banana atual (cluster_indices)\n",
    "        cluster_classes = np.take(label_class, cluster_indices)\n",
    "\n",
    "        # probs inicialmente armazena a quantidade de pontos com cada classificaﾃｧﾃ｣o e posteriormente ﾃｩ dividido pelo nﾃｺmero de pontos naquele cluster, de modo a armazenar as probabilidades em cada cluster\n",
    "        classes, probs = np.unique(cluster_classes, return_counts=True)\n",
    "        cluster_sum = np.sum(probs)\n",
    "        if classes[0]==-1:\n",
    "            probs = probs[1:]\n",
    "        probs = probs / cluster_sum\n",
    "\n",
    "        # para cada p possﾃｭvel, calcula-se o elemento do somatﾃｳrio da entropia\n",
    "        for p in probs:\n",
    "            cluster_entropy += p * np.log2(p)\n",
    "\n",
    "        # a entropia daquele cluster ﾃｩ adicionada ﾃ entropia total (com sinal negativo)\n",
    "        total_entropy -= cluster_entropy\n",
    "\n",
    "    # ﾃｩ feita a mﾃｩdia das entropias\n",
    "    total_entropy /= len(cluster_labels)\n",
    "    return total_entropy"
   ]
  },
  {
   "source": [
    "---\n",
    "## Funﾃｧﾃ｣o para plotar grﾃ｡ficos tridimensionais"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScore3D(xp, yp, zp, title, x_axis_name, y_axis_name):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    x, y = np.meshgrid(xp, yp)\n",
    "    z = zp\n",
    "\n",
    "    surf = ax.plot_surface(y, x, z, cmap=cm.coolwarm,\n",
    "                        linewidth=0, antialiased=True)           \n",
    "                        \n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    ax.set_xlabel(x_axis_name)\n",
    "    ax.set_ylabel(y_axis_name)\n",
    "    \n",
    "    # Adiciona um colorbar que mapeia os valores para diferentes cores\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## KMeans\n",
    "\n",
    "Para o classificador KMeans, os parﾃ｢metros testados sﾃ｣o:\n",
    "* Nﾃｺmero de centrﾃｳides (variﾃ｡vel \"n_clusters\") variando de 2 a 8\n",
    "* Nﾃｺmero de iteraﾃｧﾃｵes para convergﾃｪncias (variﾃ｡vel \"max_iter\") variando de 1 a 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o dicionﾃ｡rio kmc_parameters armazena os possﾃｭveis valores de parﾃ｢metros para o classificador\n",
    "kmc_parameters = {\n",
    "    \"n_clusters\": [i for i in range(2, 9)],\n",
    "    \"max_iter\": [j for j in range(1, 11)]\n",
    "}\n",
    "\n",
    "# as variﾃ｡veis com sufixo \"_size\" aramazenam o tamanho dos vetores no dicionﾃ｡rio\n",
    "cluster_size = np.shape(kmc_parameters['n_clusters'])[0]\n",
    "iter_size    = np.shape(kmc_parameters['max_iter'])[0]\n",
    "\n",
    "# com as variﾃ｡veis de sufixo \"_size\", criamos as matrizes que armazenarﾃ｣o a pontuaﾃｧﾃ｣o do classificador para todas as possﾃｭveis combinaﾃｧﾃｵes de parﾃ｢metros conforme as diferentes mﾃｩtricas de avaliaﾃｧﾃ｣o\n",
    "kmc_score_matrix_cohesion   = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_separation = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_entropy    = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_silhouette = np.zeros((cluster_size, iter_size))\n",
    "\n",
    "# iteramos por todas as possﾃｭveis combinaﾃｧﾃｵes dos parﾃ｢metros\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in kmc_parameters[\"n_clusters\"]:\n",
    "    j = 0\n",
    "    for iteration in kmc_parameters[\"max_iter\"]:\n",
    "        kmc = KMeans(n_clusters=n_cluster, max_iter=iteration).fit(X)\n",
    "        kmc_labels = kmc.labels_\n",
    "\n",
    "        # as funﾃｧﾃｵes que retornam as mﾃｩtricas de avaliaﾃｧﾃ｣o sﾃ｣o chamadas\n",
    "        cohesion    = cohesion_score(X, kmc_labels)\n",
    "        separation  = separation_score(X, kmc_labels)\n",
    "        entropy     = entropy_score(X, kmc_labels, label)\n",
    "        silhouette  = silhouette_score(X, kmc_labels, metric='euclidean')\n",
    "        \n",
    "        # a pontuaﾃｧﾃ｣o de cada mﾃｩtrica de avaliaﾃｧﾃ｣o ﾃｩ armazenada em sua matriz correspondente\n",
    "        kmc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        kmc_score_matrix_separation[i, j]   = separation\n",
    "        kmc_score_matrix_entropy[i, j]      = entropy\n",
    "        kmc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "source": [
    "Plotamos grﾃ｡ficos tridimensionais para cada mﾃｩtrica de avaliaﾃｧﾃ｣o a fim de avaliar o comportamento de cada mﾃｩtrica conforme os parﾃ｢metros do classificador sﾃ｣o modificados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_cohesion, \"KMeans - Coesﾃ｣o\\n(menor=melhor)\", \"Centroides\", \"Iteraﾃｧﾃｵes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_separation, \"KMeans - Separaﾃｧﾃ｣o\\n(maior=melhor)\", \"Centroides\", \"Iteraﾃｧﾃｵes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_entropy, \"KMeans - Entropia\\n(menor=melhor)\", \"Centroides\", \"Iteraﾃｧﾃｵes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_silhouette, \"KMeans - Silhueta\\n(maior=melhor)\", \"Centroides\", \"Iteraﾃｧﾃｵes\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/kmeans_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/kmeans_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/kmeans_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/kmeans_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A fim de verificar quais sﾃ｣o os melhores valores, estes sﾃ｣o exibidos abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KMEANS\n----------------------------------------------------------------------\nCOESﾃグ:\nA melhor pontuaﾃｧﾃ｣o (1318.315995949504) foi obtida pelos parﾃ｢metros:\n 1 iteraﾃｧﾃｵes e 2 centroides.\nSEPARAﾃﾃグ:\nA melhor pontuaﾃｧﾃ｣o (2556.4781878586577) foi obtida pelos parﾃ｢metros:\n 1 iteraﾃｧﾃｵes e 2 centroides.\nENTROPIA:\nA melhor pontuaﾃｧﾃ｣o (0.778343872214246) foi obtida pelos parﾃ｢metros:\n 1 iteraﾃｧﾃｵes e 2 centroides.\nSILHUETA:\nA melhor pontuaﾃｧﾃ｣o (0.47543358614923664) foi obtida pelos parﾃ｢metros:\n 1 iteraﾃｧﾃｵes e 2 centroides.\n"
     ]
    }
   ],
   "source": [
    "# Definimos o tamanho das matrizes que armazenam as pontuaﾃｧﾃｵes\n",
    "template_shape      = np.shape(kmc_score_matrix_cohesion)\n",
    "\n",
    "# Para cada mﾃｩtodo de avaliaﾃｧﾃ｣o, definimos a melhor pontuaﾃｧﾃ｣o para aquele mﾃｩtodo.\n",
    "# Para Coesﾃ｣o e Silhueta, as melhores pontuaﾃｧﾃｵes sﾃ｣o as maiores.\n",
    "# Jﾃ｡ para Separaﾃｧﾃ｣o e Entropia, sﾃ｣o as menores.\n",
    "maxScore_cohesion_kmeans   = np.min(kmc_score_matrix_cohesion)\n",
    "minScore_separation_kmeans = np.max(kmc_score_matrix_separation)\n",
    "minScore_entropy_kmeans    = np.min(kmc_score_matrix_entropy)\n",
    "maxScore_silhouette_kmeans = np.max(kmc_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontuaﾃｧﾃ｣o, acessamos seu ﾃｭndice na matriz de pontuaﾃｧﾃｵes para definir quais parﾃ｢metros o originaram\n",
    "index_cohesion   = np.unravel_index(np.argmin(kmc_score_matrix_cohesion), template_shape)\n",
    "index_separation = np.unravel_index(np.argmax(kmc_score_matrix_separation), template_shape)\n",
    "index_entropy    = np.unravel_index(np.argmin(kmc_score_matrix_entropy), template_shape)\n",
    "index_silhouette = np.unravel_index(np.argmax(kmc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#     DETERMINA MELHORES PARﾃMETROS PARA CADA Mﾃ欝RICA DE AVALIAﾃﾃグ\n",
    "# -------------------------------------------------------------------\n",
    "bestIter_cohesion   = kmc_parameters['max_iter'][index_cohesion[1]]\n",
    "bestN_cohesion      = kmc_parameters['n_clusters'][index_cohesion[0]]\n",
    "\n",
    "bestIter_separation = kmc_parameters['max_iter'][index_separation[1]]\n",
    "bestN_separation    = kmc_parameters['n_clusters'][index_separation[0]]\n",
    "\n",
    "bestIter_entropy    = kmc_parameters['max_iter'][index_entropy[1]]\n",
    "bestN_entropy       = kmc_parameters['n_clusters'][index_entropy[0]]\n",
    "\n",
    "bestIter_silhouette = kmc_parameters['max_iter'][index_silhouette[1]]\n",
    "bestN_silhouette    = kmc_parameters['n_clusters'][index_silhouette[0]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "print(\"KMEANS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coesﾃ｣o\n",
    "print(f\"COESﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_cohesion_kmeans}) foi obtida pelos parﾃ｢metros:\\n {bestIter_cohesion} iteraﾃｧﾃｵes e {bestN_cohesion} centroides.\")\n",
    "\n",
    "# Separaﾃｧﾃ｣o\n",
    "print(f\"SEPARAﾃﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_separation_kmeans}) foi obtida pelos parﾃ｢metros:\\n {bestIter_separation} iteraﾃｧﾃｵes e {bestN_separation} centroides.\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_entropy_kmeans}) foi obtida pelos parﾃ｢metros:\\n {bestIter_entropy} iteraﾃｧﾃｵes e {bestN_entropy} centroides.\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILHUETA:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_silhouette_kmeans}) foi obtida pelos parﾃ｢metros:\\n {bestIter_silhouette} iteraﾃｧﾃｵes e {bestN_silhouette} centroides.\")"
   ]
  },
  {
   "source": [
    "A partir dos grﾃ｡ficos gerados e dos resultados exibidos, pode-se observar, no caso do KMeans, que:\n",
    "\n",
    "* Coesﾃ｣o e Separaﾃｧﾃ｣o apresentam comportamentos bastante semelhantes em seus grﾃ｡ficos;\n",
    "* A Entropia apresenta comportamento tambﾃｩm similar ﾃ Coesﾃ｣o e Separaﾃｧﾃ｣o, mas tem seu maior valor com parﾃ｢metros diferentes daqueles da Coesﾃ｣o e Separaﾃｧﾃ｣o;\n",
    "* O classificador converge rapidamente, de modo que, no eixo grﾃ｡fico correspondente ao nﾃｺmero de iteraﾃｧﾃｵes, nota-se pouca variaﾃｧﾃ｣o, com exceﾃｧﾃ｣o apenas da Silhueta;\n",
    "* Apesar das variaﾃｧﾃｵes, as diferentes mﾃｩtricas de avaliaﾃｧﾃ｣o tﾃｪm parﾃ｢metros bastante similares para seus melhores valores."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## DBScan\n",
    "\n",
    "Para o classificador DBScan, os parﾃ｢metros testados sﾃ｣o:\n",
    "* Tamanho do raio adotado (variﾃ｡vel \"eps\")\n",
    "* Nﾃｺmero mﾃｭnimo de pontos (variﾃ｡vel \"min_samples\")\n",
    "\n",
    "Verificamos que o intervalo de valores possﾃｭveis para tais parﾃ｢metros, para que se obtenha um resultado minimamente satisfatﾃｳrio, ﾃｩ bastante restrito. Muitas combinaﾃｧﾃｵes de parﾃ｢metros faziam com que o classificador classificasse todos os pontos em uma mesma classe ou criasse um nﾃｺmero excessivo de classes (uma combinaﾃｧﾃ｣o testada resultou em mais de 100 classes).\n",
    "\n",
    "Devido a isso, delimitamos as combinaﾃｧﾃｵes de parﾃ｢metros possﾃｭveis ﾃquelas nas quais o nﾃｺmero total de classes era igual ou menor a 8 (valor escolhido por ser o maior nﾃｺmero de cores bﾃ｡sicas do MatPlotLib {R,G,B,C,M,Y,B,W}, mas que ﾃｩ um nﾃｺmero considerado grande, tendo em vista que originalmente tﾃｭnhamos apenas 2 classes) e nos quais o ponto central do cluster superior tivesse classe distinta do ponto central do cluster inferior (assim evitando uma classificaﾃｧﾃ｣o igual para todos os pontos)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a variﾃ｡vel banana_sup_index armazena a coordenada do ponto mais prﾃｳximo ﾃ coordenada (0, 1), enquanto a variﾃ｡vel banana_inf_index o faz para a coordenada (1, -0.5). Tais coordenadas foram selecionadas a partir da visualizaﾃｧﾃ｣o do grﾃ｡fico do dataset, selecionando o ponto central de cada \"banana\"\n",
    "banana_sup_index = distance.cdist(X, [[.0, 1.0]]).argmin()\n",
    "banana_inf_index = distance.cdist(X, [[1.0, -0.5]]).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicionﾃ｡rio contendo os parﾃ｢metros, onde eps varia de 0.01 a 0.15 e min_samples varia de 3 a 13\n",
    "dbs_parameters = {\n",
    "    \"eps\": [i/100 for i in range(1, 16)],\n",
    "    \"min_samples\": [i for i in range(3, 14)]\n",
    "}\n",
    "\n",
    "# a lista validate_params armazena apenas os pares de parﾃ｢metros que atendem as condiﾃｧﾃｵes descritas anteriormente\n",
    "validated_params = []\n",
    "\n",
    "# iteramos por todas as possﾃｭveis combinaﾃｧﾃｵes de parﾃ｢metros e testamos as condiﾃｧﾃｵes\n",
    "for epsx in dbs_parameters[\"eps\"]:\n",
    "    j = 0\n",
    "    for min_sample in dbs_parameters[\"min_samples\"]:\n",
    "        dbs = DBSCAN(eps=epsx, min_samples=min_sample).fit(X)\n",
    "        dbs_labels = dbs.labels_\n",
    "\n",
    "        # a primeira condiﾃｧﾃ｣o verifica se a label do centro da \"banana\" superior ﾃｩ diferente da label do centro da \"banana\" inferior\n",
    "        # a segunda condiﾃｧﾃ｣o verifica se nﾃ｣o foram geradas mais de 8 classes\n",
    "        if(dbs_labels[banana_sup_index] != dbs_labels[banana_inf_index] and len(np.unique(dbs_labels)) <= 8):\n",
    "            validated_params.append([epsx, min_sample])"
   ]
  },
  {
   "source": [
    "Os pares de parﾃ｢metros que atendem as condiﾃｧﾃｵes descritas anteriormente sﾃ｣o exibidos. Nota-se que muitas combinaﾃｧﾃｵes sﾃ｣o ignoradas por nﾃ｣o atenderem aos requisitos levantados previamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_params in validated_params:\n",
    "    plt.plot(val_params[0], val_params[1], \"k.\")\n",
    "    plt.xlabel(\"Tamanho do raio\")\n",
    "    plt.ylabel(\"Nﾃｺmero mﾃｭnimo de pontos\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "   <img src=\"./images/validated_params_plot.png\" width=400/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A partir da lista de parﾃ｢metros que atendem aos requisitos levantados, realiza-se o mesmo procedimento realizado anteriormente para extrair a pontuaﾃｧﾃ｣o do classificador para cada combinaﾃｧﾃ｣o de parﾃ｢metros, conforme cada mﾃｩtrica de avaliaﾃｧﾃ｣o."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lista ﾃｩ convertida em array do numpy\n",
    "validated_params = np.array(validated_params)\n",
    "\n",
    "unique_eps = np.unique(validated_params[:, 0]) \n",
    "unique_samples = np.unique(validated_params[:, 1]) \n",
    "\n",
    "matrix_size = ((np.shape(unique_eps)[0], np.shape(unique_samples)[0]))\n",
    "\n",
    "dbs_score_matrix_cohesion   = np.zeros(matrix_size)\n",
    "dbs_score_matrix_separation = np.zeros(matrix_size)\n",
    "dbs_score_matrix_entropy    = np.zeros(matrix_size)\n",
    "dbs_score_matrix_silhouette = np.zeros(matrix_size)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for eps in unique_eps:\n",
    "    j = 0\n",
    "    for sample in unique_samples:\n",
    "        if [eps, sample] in validated_params.tolist():\n",
    "            dbs = DBSCAN(eps=eps, min_samples=sample, n_jobs=-1).fit(X)\n",
    "            dbs_labels = dbs.labels_ \n",
    "\n",
    "            cohesion    = cohesion_score(X, dbs_labels)\n",
    "            separation  = separation_score(X, dbs_labels)\n",
    "            entropy     = entropy_score(X, dbs_labels, label)\n",
    "            silhouette  = silhouette_score(X, dbs_labels, metric='euclidean')\n",
    "            \n",
    "            dbs_score_matrix_cohesion[i, j]     = cohesion\n",
    "            dbs_score_matrix_separation[i, j]   = separation\n",
    "            dbs_score_matrix_entropy[i, j]      = entropy\n",
    "            dbs_score_matrix_silhouette[i, j]   = silhouette\n",
    "        else: \n",
    "            # como nem todos os elementos das matrizes de pontuaﾃｧﾃ｣o sﾃ｣o vﾃ｡lidos, os elementos invﾃ｡lidos sﾃ｣o definidos como Infinito\n",
    "            dbs_score_matrix_cohesion[i, j]     = float(\"inf\")\n",
    "            dbs_score_matrix_separation[i, j]   = float(\"inf\")\n",
    "            dbs_score_matrix_entropy[i, j]      = float(\"inf\")\n",
    "            dbs_score_matrix_silhouette[i, j]   = float(\"inf\")\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui, os elementos definidos como Infinito sﾃ｣o alterados para 99% do valor do menor elemento da matriz. Isso ﾃｩ realizado a fim de facilitar o plot do grﾃ｡fico tridimensional\n",
    "\n",
    "dbs_score_matrix_cohesion_ = np.where(dbs_score_matrix_cohesion == float(\"inf\"), np.min(dbs_score_matrix_cohesion)*.99, dbs_score_matrix_cohesion)\n",
    "\n",
    "dbs_score_matrix_separation_ = np.where(dbs_score_matrix_separation == float(\"inf\"), np.min(dbs_score_matrix_separation)*.99, dbs_score_matrix_separation)\n",
    "\n",
    "dbs_score_matrix_entropy_ = np.where(dbs_score_matrix_entropy == float(\"inf\"), np.min(dbs_score_matrix_entropy)*.99, dbs_score_matrix_entropy)\n",
    "\n",
    "dbs_score_matrix_silhouette_ = np.where(dbs_score_matrix_silhouette == float(\"inf\"), np.min(dbs_score_matrix_silhouette)*.99, dbs_score_matrix_silhouette)\n",
    "\n",
    "# Jﾃ｡ aqui, os elementos Infinito dos classificadores cuja melhor mﾃｩtrica ﾃｩ a mﾃ｡xima sﾃ｣o alterados para 0, a fim de nﾃ｣o atrapalhar a extraﾃｧﾃ｣o dos melhores parﾃ｢metros realizada abaixo\n",
    "dbs_score_matrix_separation = np.where(dbs_score_matrix_cohesion == float(\"inf\"), 0, dbs_score_matrix_cohesion)\n",
    "dbs_score_matrix_silhouette = np.where(dbs_score_matrix_silhouette == float(\"inf\"), 0, dbs_score_matrix_silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_cohesion_, \"DBSCAN - Coesﾃ｣o\\n(menor=melhor)\", \"Tamanho do raio\", \"Nﾃｺmero mﾃｭnimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_separation_, \"DBSCAN - Separaﾃｧﾃ｣o\\n(maior=melhor)\", \"Tamanho do raio\", \"Nﾃｺmero mﾃｭnimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_entropy_, \"DBSCAN - Entropia\", \"Tamanho do raio\\n(menor=melhor)\", \"Nﾃｺmero mﾃｭnimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_silhouette_, \"DBSCAN - Silhueta\", \"Tamanho do raio\\n(maior=melhor)\", \"Nﾃｺmero mﾃｭnimo de pontos\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/dbscan_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/dbscan_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/dbscan_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/dbscan_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DBSCAN\n----------------------------------------------------------------------\nCOESﾃグ:\nA melhor pontuaﾃｧﾃ｣o (1522.3808695570162) foi obtida pelos parﾃ｢metros:\n 0.08 tamanho de raio e 3.0 nﾃｺmero mﾃｭnimo de pontos.\n\nSEPARAﾃﾃグ:\nA melhor pontuaﾃｧﾃ｣o (1957.5406314030934) foi obtida pelos parﾃ｢metros:\n 0.09 tamanho de raio e 13.0 nﾃｺmero mﾃｭnimo de pontos.\n\nENTROPIA:\nA melhor pontuaﾃｧﾃ｣o (0.12317248547937495) foi obtida pelos parﾃ｢metros:\n 0.11 tamanho de raio e 10.0 nﾃｺmero mﾃｭnimo de pontos.\n\nSILUETA:\nA melhor pontuaﾃｧﾃ｣o (0.2516764424216868) foi obtida pelos parﾃ｢metros:\n 0.11 tamanho de raio e 10.0 nﾃｺmero mﾃｭnimo de pontos.\n\n"
     ]
    }
   ],
   "source": [
    "# O funcionamento dessa cﾃｩlula ﾃｩ o mesmo de sua cﾃｩlula equivalente do KMeans\n",
    "\n",
    "# Definimos o tamanho das matrizes que armazenam as pontuaﾃｧﾃｵes\n",
    "template_shape = np.shape(dbs_score_matrix_cohesion)\n",
    "\n",
    "# Para cada mﾃｩtodo de avaliaﾃｧﾃ｣o, definimos a melhor pontuaﾃｧﾃ｣o para aquele mﾃｩtodo.\n",
    "# Para Coesﾃ｣o e Silhueta, as melhores pontuaﾃｧﾃｵes sﾃ｣o as maiores.\n",
    "# Jﾃ｡ para Separaﾃｧﾃ｣o e Entropia, sﾃ｣o as menores.\n",
    "maxScore_cohesion_dbs   = np.min(dbs_score_matrix_cohesion)\n",
    "minScore_separation_dbs = np.max(dbs_score_matrix_separation)\n",
    "minScore_entropy_dbs    = np.min(dbs_score_matrix_entropy)\n",
    "maxScore_silhouette_dbs = np.max(dbs_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontuaﾃｧﾃ｣o, acessamos seu ﾃｭndice na matriz de pontuaﾃｧﾃｵes para definir quais parﾃ｢metros o originaram\n",
    "index_cohesion      = np.unravel_index(np.argmin(dbs_score_matrix_cohesion), template_shape)\n",
    "index_separation    = np.unravel_index(np.argmax(dbs_score_matrix_separation), template_shape)\n",
    "index_entropy       = np.unravel_index(np.argmin(dbs_score_matrix_entropy), template_shape)\n",
    "index_silhouette    = np.unravel_index(np.argmax(dbs_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#    DETERMINA MELHORES PARﾃMETROS PARA CADA Mﾃ欝RICA DE AVALIAﾃﾃグ\n",
    "# -------------------------------------------------------------------\n",
    "bestEps_cohesion            = unique_eps[index_cohesion[0]]\n",
    "bestMinSamples_cohesion     = unique_samples[index_cohesion[1]]\n",
    "\n",
    "bestEps_separation          = unique_eps[index_separation[0]]\n",
    "bestMinSamples_separation   = unique_samples[index_separation[1]]\n",
    "\n",
    "bestEps_entropy             = unique_eps[index_entropy[0]]\n",
    "bestMinSamples_entropy      = unique_samples[index_entropy[1]]\n",
    "\n",
    "bestEps_silhouette          = unique_eps[index_silhouette[0]]\n",
    "bestMinSamples_silhouette   = unique_samples[index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"DBSCAN\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coesﾃ｣o\n",
    "print(f\"COESﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_cohesion_dbs}) foi obtida pelos parﾃ｢metros:\\n {bestEps_cohesion} tamanho de raio e {bestMinSamples_cohesion} nﾃｺmero mﾃｭnimo de pontos.\\n\")\n",
    "\n",
    "# Separaﾃｧﾃ｣o\n",
    "print(f\"SEPARAﾃﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_separation_dbs}) foi obtida pelos parﾃ｢metros:\\n {bestEps_separation} tamanho de raio e {bestMinSamples_separation} nﾃｺmero mﾃｭnimo de pontos.\\n\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_entropy_dbs}) foi obtida pelos parﾃ｢metros:\\n {bestEps_entropy} tamanho de raio e {bestMinSamples_entropy} nﾃｺmero mﾃｭnimo de pontos.\\n\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILUETA:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_silhouette_dbs}) foi obtida pelos parﾃ｢metros:\\n {bestEps_silhouette} tamanho de raio e {bestMinSamples_silhouette} nﾃｺmero mﾃｭnimo de pontos.\\n\")\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "source": [
    "A partir dos grﾃ｡ficos gerados e dos resultados exibidos, pode-se observar, no caso do DBSCAN, que:\n",
    "\n",
    "* Coesﾃ｣o e Separaﾃｧﾃ｣o apresentam grﾃ｡ficos ligeiramente semelhantes, com picos e vales em posiﾃｧﾃｵes similares;\n",
    "* A Silhueta mostra, pelo seu grﾃ｡fico, ser uma ocmbinaﾃｧﾃ｣o da Separaﾃｧﾃ｣o e Silhueta, visto que seus picos e vales correspondem ora a picos e vales da Coesﾃ｣o, ora da Silhueta;\n",
    "* A Entropia apresenta um pico que representa uma regiﾃ｣o de entropia extremamente elevada, mas mantﾃｩm valores baixos para as demais combinaﾃｧﾃｵes de parﾃ｢metros;\n",
    "* Nﾃ｣o houve um consenso entre as diferentes mﾃｩtricas de quais seriam os melhores parﾃ｢metros. Ainda que Entropia e Silhueta tenham chegado aos mesmo parﾃ｢metros, as demais mﾃｩtricas chegaram a valores significativamente distintos.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## AGNES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_dict = {\n",
    "    0: \"ward\",\n",
    "    1: \"complete\",\n",
    "    2: \"single\"\n",
    "}\n",
    "\n",
    "agc_parameters = {\n",
    "    'n_clusters': [i for i in range(2, 9)],\n",
    "    'linkage': [0, 1, 2]\n",
    "}\n",
    "\n",
    "cluster_size = np.shape(agc_parameters['n_clusters'])[0]\n",
    "linkage_size = np.shape(agc_parameters['linkage'])[0]\n",
    "\n",
    "agc_score_matrix_cohesion   = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_separation = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_entropy    = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_silhouette = np.zeros((cluster_size, linkage_size))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in agc_parameters['n_clusters']:\n",
    "    j = 0\n",
    "    for linkage in agc_parameters['linkage']:\n",
    "        agc = AgglomerativeClustering(linkage=linkage_dict[linkage], n_clusters=n_cluster).fit(X)\n",
    "\n",
    "        # agc_labels = np.where(agc.labels_ == 1, 0, 1)\n",
    "        agc_labels = agc.labels_ \n",
    "\n",
    "        cohesion    = cohesion_score(X, agc_labels)\n",
    "        separation  = separation_score(X, agc_labels)\n",
    "        entropy     = entropy_score(X, agc_labels, label)\n",
    "        silhouette  = silhouette_score(X, agc_labels, metric='euclidean')\n",
    "\n",
    "        agc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        agc_score_matrix_separation[i, j]   = separation\n",
    "        agc_score_matrix_entropy[i, j]      = entropy\n",
    "        agc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_cohesion, \"AGNES - Coesﾃ｣o\\n(menor=melhor)\", \"Nﾃｺmero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_separation, \"AGNES - Separaﾃｧﾃ｣o\\n(maior=melhor)\", \"Nﾃｺmero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_entropy, \"AGNES - Entropia\\n(menor=melhor)\", \"Nﾃｺmero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_silhouette, \"AGNES - Silhueta\\n(maior=melhor)\", \"Nﾃｺmero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/agnes_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/agnes_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/agnes_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/agnes_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AGNES\n----------------------------------------------------------------------\nCOESﾃグ:\nA melhor pontuaﾃｧﾃ｣o (2874.460727893919) foi obtida pelos parﾃ｢metros:\n 2 nﾃｺmero de clusters e single medida de similaridade.\n\nSEPARAﾃﾃグ:\nA melhor pontuaﾃｧﾃ｣o (104.94433747931967) foi obtida pelos parﾃ｢metros:\n 2 nﾃｺmero de clusters e single medida de similaridade.\n\nENTROPIA:\nA melhor pontuaﾃｧﾃ｣o (0.005703878868730569) foi obtida pelos parﾃ｢metros:\n 2 nﾃｺmero de clusters e single medida de similaridade.\n\nSILUETA:\nA melhor pontuaﾃｧﾃ｣o (0.4651893317755256) foi obtida pelos parﾃ｢metros:\n 2 nﾃｺmero de clusters e ward medida de similaridade.\n\n"
     ]
    }
   ],
   "source": [
    "# O funcionamento dessa cﾃｩlula ﾃｩ o mesmo de sua cﾃｩlula equivalente do KMeans\n",
    "\n",
    "# Definimos o tamanho das matrizes que armazenam as pontuaﾃｧﾃｵes\n",
    "template_shape      = np.shape(agc_score_matrix_cohesion)\n",
    "\n",
    "# Para cada mﾃｩtodo de avaliaﾃｧﾃ｣o, definimos a melhor pontuaﾃｧﾃ｣o para aquele mﾃｩtodo.\n",
    "# Para Coesﾃ｣o e Silhueta, as melhores pontuaﾃｧﾃｵes sﾃ｣o as maiores.\n",
    "# Jﾃ｡ para Separaﾃｧﾃ｣o e Entropia, sﾃ｣o as menores.\n",
    "maxScore_cohesion_ag   = np.min(agc_score_matrix_cohesion)\n",
    "minScore_separation_ag = np.max(agc_score_matrix_separation)\n",
    "minScore_entropy_ag    = np.min(agc_score_matrix_entropy)\n",
    "maxScore_silhouette_ag = np.max(agc_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontuaﾃｧﾃ｣o, acessamos seu ﾃｭndice na matriz de pontuaﾃｧﾃｵes para definir quais parﾃ｢metros o originaram\n",
    "index_cohesion      = np.unravel_index(np.argmin(agc_score_matrix_cohesion), template_shape)\n",
    "index_separation    = np.unravel_index(np.argmax(agc_score_matrix_separation), template_shape)\n",
    "index_entropy       = np.unravel_index(np.argmin(agc_score_matrix_entropy), template_shape)\n",
    "index_silhouette    = np.unravel_index(np.argmax(agc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#    DETERMINA MELHORES PARﾃMETROS PARA CADA Mﾃ欝RICA DE AVALIAﾃﾃグ\n",
    "# -------------------------------------------------------------------\n",
    "bestNAg_cohesion            = agc_parameters['n_clusters'][index_cohesion[0]]\n",
    "bestLinkage_cohesion     = agc_parameters['linkage'][index_cohesion[1]]\n",
    "\n",
    "bestNAg_separation          = agc_parameters['n_clusters'][index_separation[0]]\n",
    "bestLinkage_separation   = agc_parameters['linkage'][index_separation[1]]\n",
    "\n",
    "bestNAg_entropy             = agc_parameters['n_clusters'][index_entropy[0]]\n",
    "bestLinkage_entropy      = agc_parameters['linkage'][index_entropy[1]]\n",
    "\n",
    "bestNAg_silhouette          = agc_parameters['n_clusters'][index_silhouette[0]]\n",
    "bestLinkage_silhouette   = agc_parameters['linkage'][index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "print(\"AGNES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coesﾃ｣o\n",
    "print(f\"COESﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_cohesion_ag}) foi obtida pelos parﾃ｢metros:\\n {bestNAg_cohesion} nﾃｺmero de clusters e {linkage_dict[bestLinkage_cohesion]} medida de similaridade.\\n\")\n",
    "\n",
    "# Separaﾃｧﾃ｣o\n",
    "print(f\"SEPARAﾃﾃグ:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_separation_ag}) foi obtida pelos parﾃ｢metros:\\n {bestNAg_separation} nﾃｺmero de clusters e {linkage_dict[bestLinkage_separation]} medida de similaridade.\\n\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontuaﾃｧﾃ｣o ({minScore_entropy_ag}) foi obtida pelos parﾃ｢metros:\\n {bestNAg_entropy} nﾃｺmero de clusters e {linkage_dict[bestLinkage_entropy]} medida de similaridade.\\n\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILUETA:\\nA melhor pontuaﾃｧﾃ｣o ({maxScore_silhouette_ag}) foi obtida pelos parﾃ｢metros:\\n {bestNAg_silhouette} nﾃｺmero de clusters e {linkage_dict[bestLinkage_silhouette]} medida de similaridade.\\n\")"
   ]
  },
  {
   "source": [
    "----\n",
    "\n",
    "## Comparaﾃｧﾃ｣o dos classificadores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             KMeans    DBScan     Agnes\n",
       "Coesﾃ｣o     1318.316  1522.381  2874.461\n",
       "Separaﾃｧﾃ｣o  2556.478  1957.541   104.944\n",
       "Entropia      0.778     0.123     0.006\n",
       "Silhueta      0.475     0.252     0.465"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KMeans</th>\n      <th>DBScan</th>\n      <th>Agnes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Coesﾃ｣o</th>\n      <td>1318.316</td>\n      <td>1522.381</td>\n      <td>2874.461</td>\n    </tr>\n    <tr>\n      <th>Separaﾃｧﾃ｣o</th>\n      <td>2556.478</td>\n      <td>1957.541</td>\n      <td>104.944</td>\n    </tr>\n    <tr>\n      <th>Entropia</th>\n      <td>0.778</td>\n      <td>0.123</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>Silhueta</th>\n      <td>0.475</td>\n      <td>0.252</td>\n      <td>0.465</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "cohesion_row = [maxScore_cohesion_kmeans,maxScore_cohesion_dbs,maxScore_cohesion_ag]\n",
    "\n",
    "separation_row = [minScore_separation_kmeans,minScore_separation_dbs,minScore_separation_ag]\n",
    "\n",
    "entropy_row = [minScore_entropy_kmeans,minScore_entropy_dbs,minScore_entropy_ag]\n",
    "\n",
    "silhouette_row = [maxScore_silhouette_kmeans,maxScore_silhouette_dbs,maxScore_silhouette_ag]\n",
    "\n",
    "storage = [\n",
    "    cohesion_row,\n",
    "    separation_row,\n",
    "    entropy_row,\n",
    "    silhouette_row\n",
    "]\n",
    "\n",
    "pd.DataFrame(storage, index=[\"Coesﾃ｣o\", \"Separaﾃｧﾃ｣o\", \"Entropia\", \"Silhueta\"], columns=[\"KMeans\", \"DBScan\", \"Agnes\"])"
   ]
  },
  {
   "source": [
    "De acordo com o critﾃｩrio de Entropia, o melhor classificador ﾃｩ o Agnes, cuja classificaﾃｧﾃ｣o ﾃｩ exibida abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc = AgglomerativeClustering(linkage=\"single\", n_clusters=2).fit(X)\n",
    "agc_labels = agc.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[agc_labels[i]])\n",
    "plt.title(\"AGNES\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_agnes.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Jﾃ｡ de acordo com os critﾃｩrios de Coesﾃ｣o, Separaﾃｧﾃ｣o e Silhueta, o melhor classificador ﾃｩ o KMeans, cuja classificaﾃｧﾃ｣o ﾃｩ exibida abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc = KMeans(n_clusters=2, max_iter=1).fit(X)\n",
    "kmc_labels = kmc.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[kmc_labels[i]])\n",
    "plt.title(\"KMeans\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_kmeans.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Todavia, ao observarmos as melhores classificaﾃｧﾃｵes do classificador DBScan, abaixo, podemos notar resultados significativamente distintos:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(eps=.11, min_samples=10, n_jobs=-1).fit(X)\n",
    "dbs_labels = dbs.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[dbs_labels[i]])\n",
    "plt.title(\"DBScan\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_dbscan.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Hipﾃｳteses Geradas\n",
    "\n",
    "### Premissa\n",
    "\n",
    "Durante todo o processo, como implementamos as funﾃｧﾃｵes (Coesﾃ｣o, Separaﾃｧﾃ｣o e Entropia) na mﾃ｣o, as verificamos mﾃｺltiplas vezes e temos certeza que estﾃ｣o funcionando conforme as explicaﾃｧﾃｵes dadas em aula. Nesse sentido, concluﾃｭmos que os resultados inusitados nﾃ｣o sejam ocasionados por um problema de implementaﾃｧﾃ｣o, mas sim por outros fatores.\n",
    "\n",
    "---\n",
    "\n",
    "### Hipﾃｳtese\n",
    "\n",
    "Antes de falar dos valores, a nossa hipﾃｳtese ﾃｩ que as mﾃｩtricas de avaliaﾃｧﾃ｣o utilizadas nﾃ｣o sﾃ｣o as mais adequadas ao nosso dataset sem que sejam realizadas modificaﾃｧﾃｵes no resultado de seus agrupamentos. Acreditamos que isso ocorra por se tratar de um dataset cujos clusters originais sﾃ｣o alongados e bastante prﾃｳximos (o que dificulta a obtenﾃｧﾃ｣o de bons agrupamentos ao se utilizar Separaﾃｧﾃ｣o, Coesﾃ｣o ou Silhueta como mﾃｩtrica) e com muitos pontos de ruﾃｭdo entre eles (o que dificulta no caso da Entropia).\n",
    "\n",
    "Segue a imagem de uma tabela que elenca os melhores resultados de cada mﾃｩtrica de avaliaﾃｧﾃ｣o para cada metﾃｳdo de agrupamento, informando os parﾃ｢metros utilizados para se chegar a tal mﾃｩtrica.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_01.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "O \"problema\" aparece quando plotamos cada um dos possﾃｭveis resultados presentes nessa tabela. Sendo, o \"problema\" em questﾃ｣o, a grande diferenﾃｧa entre o resultado dos metﾃｳdos de agrupamento que supostamente deveriam ser os melhores quando comparados com o agrupamento do dataset original. Matematicamente, sabemos que o \"grau de semelhanﾃｧa\" entre cada um dos pontos agrupados com o seu agrupamento original ﾃｩ, na realidade, a acurﾃ｡cia. Nesse sentido, para cada um dos plots dos melhores metﾃｳdos de agrupamento da tabela acima, mostramos no grﾃ｡fico qual sua acurﾃ｡cia (ainda que tal mﾃｩtrica nﾃ｣o tenha sido pedida no trabalho e nﾃ｣o seja adequada para situaﾃｧﾃｵes de aprendizado nﾃ｣o-supervisionado).\n",
    "\n",
    "O melhor KMeans para Coesﾃ｣o e Separaﾃｧﾃ｣o ﾃｩ o KMeans abaixo. Como ele tem 8 clusters distintos, fizemos um teste agrupando os clusters inferiores em um sﾃｳ, e os superiores em outro, cujo resultado ﾃｩ a imagem ao lado. Ao realizar esse agrupamento ad hoc (visto que a ordenaﾃｧﾃ｣o das classes ocorre de modo aleatﾃｳrio), conseguimos um resultado excelente para o metﾃｳdo de agrupamento. Todavia, sem tal agrupamento, o resultado obtido ﾃｩ bastante pobre.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_02.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_03.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "Comparando o melhor KMeans para estas duas mﾃｩtricas com os demais metﾃｳdos de agrupamento para as mesmas mﾃｩtricas, vemos que o melhor DBScan da Coesﾃ｣o (abaixo) tambﾃｩm realiza o agrupamento em vﾃ｡rios clusters distintos, e que, mesmo agrupando-os como feito acima, o resultado ﾃｩ inferior ao do KMeans.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_04.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_05.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "Jﾃ｡ para o DBScan da Separaﾃｧﾃ｣o, o resultado ﾃｩ bastante satisfatﾃｳrio do ponto de vista da acurﾃ｡cia. Entretanto, sua Separabilidade ﾃｩ bastante inferior ﾃ do KMeans acima (como pode ser visto na tabela).\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_06.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "Para o Agnes com melhores Coesﾃ｣o e Separabilidade, tambﾃｩm se chega a um nﾃｺmero grande de classes, conforme figura abaixo. Ao realizar o agrupamento, entretanto, chega-se ﾃ Acurﾃ｡cia mais alta obtida atﾃｩ entﾃ｣o.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_07.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_08.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "A partir disso, verificamos que os critﾃｩrios de Coesﾃ｣o e Separabilidade, por si sﾃｳs, nﾃ｣o sﾃ｣o boas mﾃｩtricas para nosso dataset, visto que o melhor metﾃｳdo de agrupamento para elas (o primeiro KMeans) apresentou um resultado bastante pobre, o qual mesmo apﾃｳs agrupamento nﾃ｣o ﾃｩ o melhor resultado do ponto de vista da similaridade com o dataset original. Alﾃｩm disso, notamos que os resultados que obtiveram um grande nﾃｺmero de classes sﾃｳ apresentaram bom resultado apﾃｳs o agrupamento, o qual nﾃ｣o foi necessﾃ｡rio para o DBScan com melhor Coesﾃ｣o. Consideramos isso bastante estranho, visto que, de todos estes metﾃｳdos de agrupamento, o DBScan da Coesﾃ｣o ﾃｩ o que tem a pior Coesﾃ｣o, mas ﾃｩ o qual, sem agrupamento posterior, realiza a melhor classificaﾃｧﾃ｣o inicial.\n",
    "\n",
    "Jﾃ｡ quanto ﾃ Entropia, o melhor resultado foi do AGNES cujo resultado ﾃｩ mostrado abaixo, ao lado do melhor DBScan para Entropia e melhor KMeans para Entropia.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_09.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_10.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_11.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "Percebe-se que o DBScan com maior Entropia ﾃｩ um metﾃｳdo de agrupamento muito melhor que o AGNES de maior Entropia.\n",
    "\n",
    "Jﾃ｡ para a mﾃｩtrica de Silhueta, o melhor resultado ﾃｩ o do KMeans exibido acima. Novamente, o DBScan de maior Silhueta apresenta resultado muito melhor, enquanto o AGNES de melhor Silhueta (abaixo) apresenta resultado bastante similar ao do KMeans, apresentando acurﾃ｡cia maior, ainda que seu valor de Silhueta tenha sido menor que a do KMeans.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_12.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "A partir do exposto, nﾃ｣o tﾃｭnhamos certeza de como proceder, tendo em vista que os melhores metﾃｳdos de agrupamento para cada mﾃｩtrica (exibidos abaixo novamente para destaque) nﾃ｣o sﾃ｣o os melhores metﾃｳdos de agrupamento obtidos.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_13.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_14.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_15.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Conclusﾃ｣o\n",
    "\n",
    "Acreditamos que ﾃｩ vﾃ｡lida a anﾃ｡lise de que tais mﾃｩtricas nﾃ｣o sﾃ｣o, na realidade, as melhores mﾃｩtricas para este dataset.\n",
    "\n",
    "Alﾃｩm disso, tudo indica que realizar o agrupamento de modo ad hoc para casos em que hﾃ｡ mais de 2 clusters ou outra base nﾃ｣o ﾃｩ vﾃ｡lido, visto que essas abordagens sﾃ｣o caracterizadas como aprendizagem nﾃ｣o supervisionado, de modo que utilizamos o agrupamento apenas para experimentaﾃｧﾃ｣o."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}