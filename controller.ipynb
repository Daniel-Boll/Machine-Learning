{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "a1bf8a58e309a98fd4c1afd359097b5c1354faf07a92acb9ef2fd44aac5a84d1"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 align=\"center\">Trabalho 2 - Aprendizagem de M√°quina</h1>\n",
    "\n",
    "## Andre Brun\n",
    "### Daniel Boll & Mateus Karvat\n",
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import style, cm\n",
    "import matplotlib.tri as mtri\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import time\n",
    "\n",
    "# Analitics\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Configurations\n",
    "style.use('ggplot')\n",
    "%matplotlib qt\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Base9.csv')\n",
    "\n",
    "# Manteremos uma c√≥pia dos dados originais\n",
    "# para garantia\n",
    "raw_data = data.copy()"
   ]
  },
  {
   "source": [
    "Separando as coordenadas x e y das labels nas vari√°veis ***X*** e ***label***"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.values[:, :2])\n",
    "label = np.array(data.values[:, 2])"
   ]
  },
  {
   "source": [
    "Plota o *dataset* com as cores verde para a primeira classe e vermelha para a segunda."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"g.\", \"r.\", \"c.\", \"b.\"] ## No caso de ter at√© 4 classes\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], colors[int(label[i])])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "## Met√≥dos de avalia√ß√£o (non-built-in)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohesion_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - N dentro de uma mesma label\n",
    "    pra cada label\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "    for lab in each_label:\n",
    "        indices = np.where(labels == lab)\n",
    "        indices = indices[0]\n",
    "\n",
    "        subX = np.take(X, indices, axis=0)\n",
    "        total += np.sum(pairwise_distances(subX, metric='sqeuclidean', n_jobs=-1))\n",
    "\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - M\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "    for lab in each_label:\n",
    "        indices_x = np.where(labels == lab)\n",
    "        indices_x = indices_x[0]\n",
    "\n",
    "        indices_y = np.where(labels != lab)\n",
    "        indices_y = indices_y[0]\n",
    "\n",
    "        \n",
    "        subX = np.take(X, indices_x, axis=0)\n",
    "        subY = np.take(X, indices_y, axis=0)\n",
    "\n",
    "        total += np.sum(pairwise_distances(subX, subY, metric='sqeuclidean', n_jobs=-1))\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_score(X, label_class, label_dataset):\n",
    "    \"\"\"\n",
    "        banana üçå\n",
    "        B1 = label_dataset == 1\n",
    "        B2 = label_dataset == 0\n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(label_dataset)\n",
    "    total_entropy = 0\n",
    "    for label in cluster_labels:\n",
    "        cluster_entropy = 0\n",
    "        # Cluster indices tem o √≠ndice\n",
    "        # de uma banana (dataset original)\n",
    "        cluster_indices = np.where(label_dataset == label)\n",
    "        cluster_indices = cluster_indices[0]\n",
    "\n",
    "        # Tem todas as inst√¢ncias da label_class\n",
    "        # dentro da banana atual (cluster_indices)\n",
    "        cluster_classes = np.take(label_class, cluster_indices)\n",
    "        probs = np.unique(cluster_classes, return_counts=True)[1]\n",
    "        probs = probs / np.sum(probs)\n",
    "        for p in probs:\n",
    "            cluster_entropy += p * np.log2(p)\n",
    "\n",
    "        total_entropy += cluster_entropy\n",
    "\n",
    "        total_entropy /= -len(cluster_labels)\n",
    "    return total_entropy"
   ]
  },
  {
   "source": [
    "---"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScore3D(xp, yp, zp, title):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    x, y = np.meshgrid(xp, yp)\n",
    "    z = zp\n",
    "\n",
    "    surf = ax.plot_surface(y, x, z, cmap=cm.coolwarm,\n",
    "                        linewidth=0, antialiased=True)           \n",
    "                        \n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    # Add a color bar which maps values to colors.\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## KMeans"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc_parameters = {\n",
    "    \"n_clusters\": [i for i in range(2, 9)],\n",
    "    \"max_iter\": [j for j in range(1, 11)]\n",
    "}\n",
    "\n",
    "cluster_size = np.shape(kmc_parameters['n_clusters'])[0]\n",
    "iter_size    = np.shape(kmc_parameters['max_iter'])[0]\n",
    "\n",
    "kmc_score_matrix_cohesion   = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_separation = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_entropy    = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_silhouette = np.zeros((cluster_size, iter_size))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in kmc_parameters[\"n_clusters\"]:\n",
    "    j = 0\n",
    "    for iteration in kmc_parameters[\"max_iter\"]:\n",
    "        kmc = KMeans(n_clusters=n_cluster, max_iter=iteration).fit(X)\n",
    "\n",
    "        kmc_labels = kmc.labels_\n",
    "\n",
    "        cohesion    = cohesion_score(X, kmc_labels)\n",
    "        separation  = separation_score(X, kmc_labels)\n",
    "        entropy     = entropy_score(X, kmc_labels, label)\n",
    "        silhouette  = silhouette_score(X, kmc_labels, metric='euclidean')\n",
    "        \n",
    "        kmc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        kmc_score_matrix_separation[i, j]   = separation\n",
    "        kmc_score_matrix_entropy[i, j]      = entropy\n",
    "        kmc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_cohesion, \"Cohesion\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_separation, \"Separation\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_entropy, \"Entropy\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_silhouette, \"Silhouette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the template data\n",
    "template_shape      = np.shape(kmc_score_matrix_cohesion)\n",
    "\n",
    "# Get the best score to each evaluation method\n",
    "maxScore_cohesion_kmeans   = np.max(kmc_score_matrix_cohesion)\n",
    "minScore_separation_kmeans = np.min(kmc_score_matrix_separation)\n",
    "minScore_entropy_kmeans    = np.min(kmc_score_matrix_entropy)\n",
    "maxScore_silhouette_kmeans = np.max(kmc_score_matrix_silhouette)\n",
    "\n",
    "# Get the index of this score, so we can access the specific\n",
    "# parameter.\n",
    "index_cohesion      = np.unravel_index(np.argmax(kmc_score_matrix_cohesion), template_shape)\n",
    "\n",
    "index_separation    = np.unravel_index(np.argmin(kmc_score_matrix_separation), template_shape)\n",
    "\n",
    "index_entropy       = np.unravel_index(np.argmin(kmc_score_matrix_entropy), template_shape)\n",
    "\n",
    "index_silhouette    = np.unravel_index(np.argmax(kmc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#           GET THE BEST PARAMATERS FOR EACH EVALUATION METHOD\n",
    "# -------------------------------------------------------------------\n",
    "bestIter_cohesion   = kmc_parameters['max_iter'][index_cohesion[1]]\n",
    "bestN_cohesion      = kmc_parameters['n_clusters'][index_cohesion[0]]\n",
    "\n",
    "bestIter_separation = kmc_parameters['max_iter'][index_separation[1]]\n",
    "bestN_separation    = kmc_parameters['n_clusters'][index_separation[0]]\n",
    "\n",
    "bestIter_entropy    = kmc_parameters['max_iter'][index_entropy[1]]\n",
    "bestN_entropy       = kmc_parameters['n_clusters'][index_entropy[0]]\n",
    "\n",
    "bestIter_silhouette = kmc_parameters['max_iter'][index_silhouette[1]]\n",
    "bestN_silhouette    = kmc_parameters['n_clusters'][index_silhouette[0]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cohesion\n",
    "print(f\"COHESION:\\nThe best score ({maxScore_cohesion_kmeans}) was acquired by the parameters:\\n {bestIter_cohesion} iterations and {bestN_cohesion} clusters.\")\n",
    "\n",
    "# Separation\n",
    "print(f\"SEPARATION:\\nThe best score ({minScore_separation_kmeans}) was acquired by the parameters:\\n {bestIter_separation} iterations and {bestN_separation} clusters.\")\n",
    "\n",
    "# Entropy\n",
    "print(f\"ENTROPY:\\nThe best score ({minScore_entropy_kmeans}) was acquired by the parameters:\\n {bestIter_entropy} iterations and {bestN_entropy} clusters.\")\n",
    "\n",
    "# Silhouette\n",
    "print(f\"SILHOUETTE:\\nThe best score ({maxScore_silhouette_kmeans}) was acquired by the parameters:\\n {bestIter_silhouette} iterations and {bestN_silhouette} clusters.\")\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "source": [
    "---\n",
    "## DBScan"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banana_sup_index = distance.cdist(X, [[.0, 1.0]]).argmin()\n",
    "banana_inf_index = distance.cdist(X, [[1.0, -0.5]]).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs_parameters = {\n",
    "    \"eps\": [i/100 for i in range(1, 16)],\n",
    "    \"min_samples\": [i for i in range(3, 14)]\n",
    "}\n",
    "\n",
    "validated_params = []\n",
    "\n",
    "for epsx in dbs_parameters[\"eps\"]:\n",
    "    j = 0\n",
    "    for min_sample in dbs_parameters[\"min_samples\"]:\n",
    "        dbs = DBSCAN(eps=epsx, min_samples=min_sample).fit(X)\n",
    "        dbs_labels = dbs.labels_\n",
    "\n",
    "        if(dbs_labels[banana_sup_index] != dbs_labels[banana_inf_index] and len(np.unique(dbs_labels)) <= 8):\n",
    "            validated_params.append([epsx, min_sample])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_params in validated_params:\n",
    "    plt.plot(val_params[0], val_params[1], \"k.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_params = np.array(validated_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_eps = np.unique(validated_params[:, 0]) \n",
    "unique_samples = np.unique(validated_params[:, 1]) \n",
    "\n",
    "matrix_size = ((np.shape(unique_eps)[0], np.shape(unique_samples)[0]))\n",
    "\n",
    "dbs_score_matrix_cohesion   = np.zeros(matrix_size)\n",
    "dbs_score_matrix_separation = np.zeros(matrix_size)\n",
    "dbs_score_matrix_entropy    = np.zeros(matrix_size)\n",
    "dbs_score_matrix_silhouette = np.zeros(matrix_size)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for eps in unique_eps:\n",
    "    j = 0\n",
    "    for sample in unique_samples:\n",
    "        if [eps, sample] in validated_params.tolist():\n",
    "            dbs = DBSCAN(eps=eps, min_samples=sample, n_jobs=-1).fit(X)\n",
    "\n",
    "            dbs_labels = dbs.labels_ # <- Problema est√° aqui\n",
    "\n",
    "            cohesion    = cohesion_score(X, dbs_labels)\n",
    "            separation  = separation_score(X, dbs_labels)\n",
    "            entropy     = entropy_score(X, dbs_labels, label)\n",
    "            silhouette  = silhouette_score(X, dbs_labels, metric='euclidean')\n",
    "            \n",
    "            dbs_score_matrix_cohesion[i, j]     = cohesion\n",
    "            dbs_score_matrix_separation[i, j]   = separation\n",
    "            dbs_score_matrix_entropy[i, j]      = entropy\n",
    "            dbs_score_matrix_silhouette[i, j]   = silhouette\n",
    "        else: \n",
    "            dbs_score_matrix_cohesion[i, j]     = float(\"inf\")\n",
    "            dbs_score_matrix_separation[i, j]   = float(\"inf\")\n",
    "            dbs_score_matrix_entropy[i, j]      = float(\"inf\")\n",
    "            dbs_score_matrix_silhouette[i, j]   = float(\"inf\")\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DÕóÃáÕ™Õ¢Ã§ÃòÕáÕéÕîOÕ™ÕßÃõÃ±ÕàÕáÕöÃ∞ÕìÃñ ÃöÃæÃáÕõÃßÃ´ÕéÃÆNÕ≠Õ©ÃΩÕ†ÃúÕîÕÖÕéOÃîÃîÕ´ÕØÕüÃ¶ÕéÕöÕîÃÆÕîÃüÃØTÕåÃöÕÅÕàÃúÃüÃ´ÃòÃ™Ã™ ÕÉÃäÃÖÃ®Ã∫Ã™Ã§Ã¶AÕ≠ÕÄÃóÃúÕïÃ±ÃûÃÆÃ™SÃëÃîÕóÕåÃßÃúÃûÕîÕöKÃÅÕÅÕöÃñÃù\n",
    "\n",
    "\n",
    "dbs_score_matrix_cohesion_ = np.where(dbs_score_matrix_cohesion == float(\"inf\"), np.min(dbs_score_matrix_cohesion)*.99, dbs_score_matrix_cohesion)\n",
    "\n",
    "dbs_score_matrix_separation_ = np.where(dbs_score_matrix_separation == float(\"inf\"), np.min(dbs_score_matrix_separation)*.99, dbs_score_matrix_separation)\n",
    "\n",
    "dbs_score_matrix_entropy_ = np.where(dbs_score_matrix_entropy == float(\"inf\"), np.min(dbs_score_matrix_entropy)*.99, dbs_score_matrix_entropy)\n",
    "\n",
    "dbs_score_matrix_silhouette_ = np.where(dbs_score_matrix_silhouette == float(\"inf\"), np.min(dbs_score_matrix_silhouette)*.99, dbs_score_matrix_silhouette)\n",
    "\n",
    "\n",
    "dbs_score_matrix_cohesion = np.where(dbs_score_matrix_cohesion == float(\"inf\"), 0, dbs_score_matrix_cohesion)\n",
    "dbs_score_matrix_silhouette = np.where(dbs_score_matrix_silhouette == float(\"inf\"), 0, dbs_score_matrix_silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_cohesion_, \"Cohesion\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_separation_, \"Separation\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_entropy_, \"Entropy\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_silhouette_, \"Silhouette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the template data\n",
    "template_shape      = np.shape(dbs_score_matrix_cohesion)\n",
    "\n",
    "# Get the best score to each evaluation method\n",
    "maxScore_cohesion_dbs   = np.max(dbs_score_matrix_cohesion)\n",
    "minScore_separation_dbs = np.min(dbs_score_matrix_separation)\n",
    "minScore_entropy_dbs    = np.min(dbs_score_matrix_entropy)\n",
    "maxScore_silhouette_dbs = np.max(dbs_score_matrix_silhouette)\n",
    "\n",
    "# Get the index of this score, so we can access the specific\n",
    "# parameter.\n",
    "index_cohesion      = np.unravel_index(np.argmax(dbs_score_matrix_cohesion), template_shape)\n",
    "\n",
    "index_separation    = np.unravel_index(np.argmin(dbs_score_matrix_separation), template_shape)\n",
    "\n",
    "index_entropy       = np.unravel_index(np.argmin(dbs_score_matrix_entropy), template_shape)\n",
    "\n",
    "index_silhouette    = np.unravel_index(np.argmax(dbs_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#           GET THE BEST PARAMATERS FOR EACH EVALUATION METHOD\n",
    "# -------------------------------------------------------------------\n",
    "bestEps_cohesion            = unique_eps[index_cohesion[0]]\n",
    "bestMinSamples_cohesion     = unique_samples[index_cohesion[1]]\n",
    "\n",
    "bestEps_separation          = unique_eps[index_separation[0]]\n",
    "bestMinSamples_separation   = unique_samples[index_separation[1]]\n",
    "\n",
    "bestEps_entropy             = unique_eps[index_entropy[0]]\n",
    "bestMinSamples_entropy      = unique_samples[index_entropy[1]]\n",
    "\n",
    "bestEps_silhouette          = unique_eps[index_silhouette[0]]\n",
    "bestMinSamples_silhouette   = unique_samples[index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cohesion\n",
    "print(f\"COHESION:\\nThe best score ({maxScore_cohesion_dbs}) was acquired by the parameters:\\n {bestEps_cohesion} eps value and {bestMinSamples_cohesion} samples.\\n\")\n",
    "\n",
    "# Separation\n",
    "print(f\"SEPARATION:\\nThe best score ({minScore_separation_dbs}) was acquired by the parameters:\\n {bestEps_separation} eps value and {bestMinSamples_separation} samples.\\n\")\n",
    "\n",
    "# Entropy\n",
    "print(f\"ENTROPY:\\nThe best score ({minScore_entropy_dbs}) was acquired by the parameters:\\n {bestEps_entropy} eps value and {bestMinSamples_entropy} samples.\\n\")\n",
    "\n",
    "# Silhouette\n",
    "print(f\"SILHOUETTE:\\nThe best score ({maxScore_silhouette_dbs}) was acquired by the parameters:\\n {bestEps_silhouette} eps value and {bestMinSamples_silhouette} samples.\\n\")\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "source": [
    "---\n",
    "## AGNES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_dict = {\n",
    "    0: \"ward\",\n",
    "    1: \"complete\",\n",
    "    2: \"single\"\n",
    "}\n",
    "\n",
    "agc_parameters = {\n",
    "    'n_clusters': [i for i in range(2, 9)],\n",
    "    'linkage': [0, 1, 2]\n",
    "}\n",
    "\n",
    "cluster_size = np.shape(agc_parameters['n_clusters'])[0]\n",
    "linkage_size = np.shape(agc_parameters['linkage'])[0]\n",
    "\n",
    "agc_score_matrix_cohesion   = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_separation = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_entropy    = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_silhouette = np.zeros((cluster_size, linkage_size))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in agc_parameters['n_clusters']:\n",
    "    j = 0\n",
    "    for linkage in agc_parameters['linkage']:\n",
    "        agc = AgglomerativeClustering(linkage=linkage_dict[linkage], n_clusters=n_cluster).fit(X)\n",
    "\n",
    "        # agc_labels = np.where(agc.labels_ == 1, 0, 1)\n",
    "        agc_labels = agc.labels_ \n",
    "\n",
    "        cohesion    = cohesion_score(X, agc_labels)\n",
    "        separation  = separation_score(X, agc_labels)\n",
    "        entropy     = entropy_score(X, agc_labels, label)\n",
    "        silhouette  = silhouette_score(X, agc_labels, metric='euclidean')\n",
    "\n",
    "        agc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        agc_score_matrix_separation[i, j]   = separation\n",
    "        agc_score_matrix_entropy[i, j]      = entropy\n",
    "        agc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_cohesion, \"Cohesion\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_separation, \"Separation\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_entropy, \"Entropy\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_silhouette, \"Silhouette\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the template data\n",
    "template_shape      = np.shape(agc_score_matrix_cohesion)\n",
    "\n",
    "# Get the best score to each evaluation method\n",
    "maxScore_cohesion_ag   = np.max(agc_score_matrix_cohesion)\n",
    "minScore_separation_ag = np.min(agc_score_matrix_separation)\n",
    "minScore_entropy_ag    = np.min(agc_score_matrix_entropy)\n",
    "maxScore_silhouette_ag = np.max(agc_score_matrix_silhouette)\n",
    "\n",
    "# Get the index of this score, so we can access the specific\n",
    "# parameter.\n",
    "index_cohesion      = np.unravel_index(np.argmax(agc_score_matrix_cohesion), template_shape)\n",
    "\n",
    "index_separation    = np.unravel_index(np.argmin(agc_score_matrix_separation), template_shape)\n",
    "\n",
    "index_entropy       = np.unravel_index(np.argmin(agc_score_matrix_entropy), template_shape)\n",
    "\n",
    "index_silhouette    = np.unravel_index(np.argmax(agc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#           GET THE BEST PARAMATERS FOR EACH EVALUATION METHOD\n",
    "# -------------------------------------------------------------------\n",
    "bestNAg_cohesion            = agc_parameters['n_clusters'][index_cohesion[0]]\n",
    "bestLinkage_cohesion     = agc_parameters['linkage'][index_cohesion[1]]\n",
    "\n",
    "bestNAg_separation          = agc_parameters['n_clusters'][index_separation[0]]\n",
    "bestLinkage_separation   = agc_parameters['linkage'][index_separation[1]]\n",
    "\n",
    "bestNAg_entropy             = agc_parameters['n_clusters'][index_entropy[0]]\n",
    "bestLinkage_entropy      = agc_parameters['linkage'][index_entropy[1]]\n",
    "\n",
    "bestNAg_silhouette          = agc_parameters['n_clusters'][index_silhouette[0]]\n",
    "bestLinkage_silhouette   = agc_parameters['linkage'][index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Cohesion\n",
    "print(f\"COHESION:\\nThe best score ({maxScore_cohesion_ag}) was acquired by the parameters:\\n {bestNAg_cohesion} clusters number and {linkage_dict[bestLinkage_cohesion]} method.\\n\")\n",
    "\n",
    "# Separation\n",
    "print(f\"SEPARATION:\\nThe best score ({minScore_separation_ag}) was acquired by the parameters:\\n {bestNAg_separation} clusters number and {linkage_dict[bestLinkage_separation]} method.\\n\")\n",
    "\n",
    "# Entropy\n",
    "print(f\"ENTROPY:\\nThe best score ({minScore_entropy_ag}) was acquired by the parameters:\\n {bestNAg_entropy} clusters number and {linkage_dict[bestLinkage_entropy]} method.\\n\")\n",
    "\n",
    "# Silhouette\n",
    "print(f\"SILHOUETTE:\\nThe best score ({maxScore_silhouette_ag}) was acquired by the parameters:\\n {bestNAg_silhouette} clusters number and {linkage_dict[bestLinkage_silhouette]} method.\\n\")\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc = AgglomerativeClustering(linkage=\"single\", n_clusters=2).fit(X)\n",
    "agc_labels = agc.labels_\n",
    "\n",
    "print(cohesion_score(X, agc_labels))\n",
    "print(separation_score(X, agc_labels))\n",
    "print(entropy_score(X, agc_labels, label))\n",
    "print(silhouette_score(X, agc_labels))\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[agc_labels[i]])\n",
    "plt.title(accuracy_score(label, agc_labels))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "### asas"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cohesion_row = [maxScore_cohesion_kmeans,maxScore_cohesion_dbs,maxScore_cohesion_ag]\n",
    "\n",
    "separation_row = [minScore_separation_kmeans,minScore_separation_dbs,minScore_separation_ag]\n",
    "\n",
    "entropy_row = [minScore_entropy_kmeans,minScore_entropy_dbs,minScore_entropy_ag]\n",
    "\n",
    "silhouette_row = [maxScore_silhouette_kmeans,maxScore_silhouette_dbs,maxScore_silhouette_ag]\n",
    "\n",
    "storage = [\n",
    "    cohesion_row,\n",
    "    separation_row,\n",
    "    entropy_row,\n",
    "    silhouette_row\n",
    "]\n",
    "\n",
    "pd.DataFrame(storage, index=[\"Cohesion\", \"Separation\", \"Entropy\", \"Silhouette\"], columns=[\"KMeans\", \"DBScan\", \"Agnes\"])"
   ]
  }
 ]
}