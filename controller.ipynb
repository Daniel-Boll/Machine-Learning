{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "deeplearning",
   "display_name": "(Conda) DL",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h1 align=\"center\">Trabalho 2 - Aprendizagem de M√°quina</h1>\n",
    "\n",
    "## Andre Brun\n",
    "### Daniel Boll & Mateus Karvat\n",
    "---\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Inicialmente, importamos as bibliotecas necess√°rias."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import LinearLocator, FormatStrFormatter\n",
    "from matplotlib import style, cm\n",
    "import matplotlib.tri as mtri\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import time\n",
    "\n",
    "# Analitics\n",
    "from sklearn.metrics import accuracy_score, silhouette_score, pairwise_distances\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "# Clusters\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Configurations\n",
    "style.use('ggplot')\n",
    "%matplotlib qt\n",
    "np.set_printoptions(precision=3, suppress=True)\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "source": [
    "Em seguida, carregamos a base de dados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Base9.csv')\n",
    "\n",
    "# Manteremos uma c√≥pia dos dados originais\n",
    "# para garantia\n",
    "raw_data = data.copy()"
   ]
  },
  {
   "source": [
    "Separando as coordenadas x e y na vari√°vel ***X*** e as labels na vari√°vel ***label***."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(data.values[:, :2])\n",
    "label = np.array(data.values[:, 2])"
   ]
  },
  {
   "source": [
    "Ap√≥s carregar a base e separ√°-la, plotamos o *dataset* com as cores verde para a primeira classe e vermelha para a segunda. O dataset √© popularmente chamado de \"Banana\", de modo que ocasionalmente nos referimos a cada cluster como uma \"banana\"."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"g.\", \"r.\", \"c.\", \"b.\"] ## No caso de ter at√© 4 classes\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], colors[int(label[i])])\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/dataset_plot.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Metricas de avalia√ß√£o \n",
    "\n",
    "Fun√ß√µes implementadas por n√≥s para as m√©tricas de avalia√ß√£o n√£o implementadas pelas bibliotecas utilizadas. A m√©trica de Silhueta √© utilizada a partir de fun√ß√£o pr√©-pronta do SciKit Learn."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Coes√£o"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cohesion_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - N dentro de uma mesma label\n",
    "    pra cada label definida pelo classificador\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "\n",
    "    # para cada label, obtemos a matriz subX, que cont√©m as coordenadas dos pontos daquelas labels\n",
    "    for lab in each_label:\n",
    "        if lab!=-1:\n",
    "            indices = np.where(labels == lab)\n",
    "            indices = indices[0]\n",
    "            subX = np.take(X, indices, axis=0)\n",
    "\n",
    "            # verificamos a dist√¢ncia euclidiana entre todos os pares de pontos em subX\n",
    "            total += np.sum(pairwise_distances(subX, metric='sqeuclidean', n_jobs=-1))\n",
    "\n",
    "    # a fim de reduzir a dimens√£o do resultado, retornarmos sua raiz quadrada\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "source": [
    "### Separa√ß√£o"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separation_score(X, labels):\n",
    "    \"\"\"\n",
    "    N - M\n",
    "    \"\"\"\n",
    "    each_label = np.unique(labels)\n",
    "    total = 0\n",
    "    \n",
    "    # assim como na coes√£o, obtemos a matriz subX com os pontos pertencentes a uma mesma label. Por√©m, aqui precisamos da matriz subY com os pontos pertencentes √†s demais labels.\n",
    "    for lab in each_label:\n",
    "        if lab!=-1:\n",
    "            indices_x = np.where(labels == lab)\n",
    "            indices_x = indices_x[0]\n",
    "\n",
    "            indices_y = np.where(np.logical_and(labels != lab, labels!=-1))\n",
    "            indices_y = indices_y[0]\n",
    "            \n",
    "            subX = np.take(X, indices_x, axis=0)\n",
    "            subY = np.take(X, indices_y, axis=0)\n",
    "\n",
    "            # calculamos a dist√¢ncia entre os pontos de subX e os pontos de subY\n",
    "            total += np.sum(pairwise_distances(subX, subY, metric='sqeuclidean', n_jobs=-1))\n",
    "    return np.sqrt(total)"
   ]
  },
  {
   "source": [
    "### Entropia"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy_score(X, label_class, label_dataset):\n",
    "    \"\"\"\n",
    "        banana üçå\n",
    "        B1 = label_dataset == 1\n",
    "        B2 = label_dataset == 0\n",
    "    \"\"\"\n",
    "    cluster_labels = np.unique(label_dataset)\n",
    "    total_entropy = 0\n",
    "    for label in cluster_labels:\n",
    "        cluster_entropy = 0\n",
    "        \n",
    "        # Cluster indices tem o √≠ndice\n",
    "        # de uma banana (dataset original)\n",
    "        cluster_indices = np.where(label_dataset == label)\n",
    "        cluster_indices = cluster_indices[0]\n",
    "\n",
    "        # Tem todas as inst√¢ncias da label_class\n",
    "        # dentro da banana atual (cluster_indices)\n",
    "        cluster_classes = np.take(label_class, cluster_indices)\n",
    "\n",
    "        # probs inicialmente armazena a quantidade de pontos com cada classifica√ß√£o e posteriormente √© dividido pelo n√∫mero de pontos naquele cluster, de modo a armazenar as probabilidades em cada cluster\n",
    "        classes, probs = np.unique(cluster_classes, return_counts=True)\n",
    "        cluster_sum = np.sum(probs)\n",
    "        if classes[0]==-1:\n",
    "            probs = probs[1:]\n",
    "        probs = probs / cluster_sum\n",
    "\n",
    "        # para cada p poss√≠vel, calcula-se o elemento do somat√≥rio da entropia\n",
    "        for p in probs:\n",
    "            cluster_entropy += p * np.log2(p)\n",
    "\n",
    "        # a entropia daquele cluster √© adicionada √† entropia total (com sinal negativo)\n",
    "        total_entropy -= cluster_entropy\n",
    "\n",
    "    # √© feita a m√©dia das entropias\n",
    "    total_entropy /= len(cluster_labels)\n",
    "    return total_entropy"
   ]
  },
  {
   "source": [
    "---\n",
    "## Fun√ß√£o para plotar gr√°ficos tridimensionais"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotScore3D(xp, yp, zp, title, x_axis_name, y_axis_name):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "    x, y = np.meshgrid(xp, yp)\n",
    "    z = zp\n",
    "\n",
    "    surf = ax.plot_surface(y, x, z, cmap=cm.coolwarm,\n",
    "                        linewidth=0, antialiased=True)           \n",
    "                        \n",
    "    ax.zaxis.set_major_locator(LinearLocator(10))\n",
    "    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n",
    "    ax.set_xlabel(x_axis_name)\n",
    "    ax.set_ylabel(y_axis_name)\n",
    "    \n",
    "    # Adiciona um colorbar que mapeia os valores para diferentes cores\n",
    "    fig.colorbar(surf, shrink=0.5, aspect=5)\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "source": [
    "---\n",
    "\n",
    "## KMeans\n",
    "\n",
    "Para o classificador KMeans, os par√¢metros testados s√£o:\n",
    "* N√∫mero de centr√≥ides (vari√°vel \"n_clusters\") variando de 2 a 8\n",
    "* N√∫mero de itera√ß√µes para converg√™ncias (vari√°vel \"max_iter\") variando de 1 a 10"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# o dicion√°rio kmc_parameters armazena os poss√≠veis valores de par√¢metros para o classificador\n",
    "kmc_parameters = {\n",
    "    \"n_clusters\": [i for i in range(2, 9)],\n",
    "    \"max_iter\": [j for j in range(1, 11)]\n",
    "}\n",
    "\n",
    "# as vari√°veis com sufixo \"_size\" aramazenam o tamanho dos vetores no dicion√°rio\n",
    "cluster_size = np.shape(kmc_parameters['n_clusters'])[0]\n",
    "iter_size    = np.shape(kmc_parameters['max_iter'])[0]\n",
    "\n",
    "# com as vari√°veis de sufixo \"_size\", criamos as matrizes que armazenar√£o a pontua√ß√£o do classificador para todas as poss√≠veis combina√ß√µes de par√¢metros conforme as diferentes m√©tricas de avalia√ß√£o\n",
    "kmc_score_matrix_cohesion   = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_separation = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_entropy    = np.zeros((cluster_size, iter_size))\n",
    "kmc_score_matrix_silhouette = np.zeros((cluster_size, iter_size))\n",
    "\n",
    "# iteramos por todas as poss√≠veis combina√ß√µes dos par√¢metros\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in kmc_parameters[\"n_clusters\"]:\n",
    "    j = 0\n",
    "    for iteration in kmc_parameters[\"max_iter\"]:\n",
    "        kmc = KMeans(n_clusters=n_cluster, max_iter=iteration).fit(X)\n",
    "        kmc_labels = kmc.labels_\n",
    "\n",
    "        # as fun√ß√µes que retornam as m√©tricas de avalia√ß√£o s√£o chamadas\n",
    "        cohesion    = cohesion_score(X, kmc_labels)\n",
    "        separation  = separation_score(X, kmc_labels)\n",
    "        entropy     = entropy_score(X, kmc_labels, label)\n",
    "        silhouette  = silhouette_score(X, kmc_labels, metric='euclidean')\n",
    "        \n",
    "        # a pontua√ß√£o de cada m√©trica de avalia√ß√£o √© armazenada em sua matriz correspondente\n",
    "        kmc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        kmc_score_matrix_separation[i, j]   = separation\n",
    "        kmc_score_matrix_entropy[i, j]      = entropy\n",
    "        kmc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "source": [
    "Plotamos gr√°ficos tridimensionais para cada m√©trica de avalia√ß√£o a fim de avaliar o comportamento de cada m√©trica conforme os par√¢metros do classificador s√£o modificados."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_cohesion, \"KMeans - Coes√£o\\n(menor=melhor)\", \"Centroides\", \"Itera√ß√µes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_separation, \"KMeans - Separa√ß√£o\\n(maior=melhor)\", \"Centroides\", \"Itera√ß√µes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_entropy, \"KMeans - Entropia\\n(menor=melhor)\", \"Centroides\", \"Itera√ß√µes\")\n",
    "\n",
    "plotScore3D(kmc_parameters['max_iter'], kmc_parameters['n_clusters'], kmc_score_matrix_silhouette, \"KMeans - Silhueta\\n(maior=melhor)\", \"Centroides\", \"Itera√ß√µes\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/kmeans_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/kmeans_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/kmeans_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/kmeans_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A fim de verificar quais s√£o os melhores valores, estes s√£o exibidos abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KMEANS\n----------------------------------------------------------------------\nCOES√ÉO:\nA melhor pontua√ß√£o (1318.315995949504) foi obtida pelos par√¢metros:\n 1 itera√ß√µes e 2 centroides.\nSEPARA√á√ÉO:\nA melhor pontua√ß√£o (2556.4781878586577) foi obtida pelos par√¢metros:\n 1 itera√ß√µes e 2 centroides.\nENTROPIA:\nA melhor pontua√ß√£o (0.778343872214246) foi obtida pelos par√¢metros:\n 1 itera√ß√µes e 2 centroides.\nSILHUETA:\nA melhor pontua√ß√£o (0.47543358614923664) foi obtida pelos par√¢metros:\n 1 itera√ß√µes e 2 centroides.\n"
     ]
    }
   ],
   "source": [
    "# Definimos o tamanho das matrizes que armazenam as pontua√ß√µes\n",
    "template_shape      = np.shape(kmc_score_matrix_cohesion)\n",
    "\n",
    "# Para cada m√©todo de avalia√ß√£o, definimos a melhor pontua√ß√£o para aquele m√©todo.\n",
    "# Para Coes√£o e Silhueta, as melhores pontua√ß√µes s√£o as maiores.\n",
    "# J√° para Separa√ß√£o e Entropia, s√£o as menores.\n",
    "maxScore_cohesion_kmeans   = np.min(kmc_score_matrix_cohesion)\n",
    "minScore_separation_kmeans = np.max(kmc_score_matrix_separation)\n",
    "minScore_entropy_kmeans    = np.min(kmc_score_matrix_entropy)\n",
    "maxScore_silhouette_kmeans = np.max(kmc_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontua√ß√£o, acessamos seu √≠ndice na matriz de pontua√ß√µes para definir quais par√¢metros o originaram\n",
    "index_cohesion   = np.unravel_index(np.argmin(kmc_score_matrix_cohesion), template_shape)\n",
    "index_separation = np.unravel_index(np.argmax(kmc_score_matrix_separation), template_shape)\n",
    "index_entropy    = np.unravel_index(np.argmin(kmc_score_matrix_entropy), template_shape)\n",
    "index_silhouette = np.unravel_index(np.argmax(kmc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#     DETERMINA MELHORES PAR√ÇMETROS PARA CADA M√âTRICA DE AVALIA√á√ÉO\n",
    "# -------------------------------------------------------------------\n",
    "bestIter_cohesion   = kmc_parameters['max_iter'][index_cohesion[1]]\n",
    "bestN_cohesion      = kmc_parameters['n_clusters'][index_cohesion[0]]\n",
    "\n",
    "bestIter_separation = kmc_parameters['max_iter'][index_separation[1]]\n",
    "bestN_separation    = kmc_parameters['n_clusters'][index_separation[0]]\n",
    "\n",
    "bestIter_entropy    = kmc_parameters['max_iter'][index_entropy[1]]\n",
    "bestN_entropy       = kmc_parameters['n_clusters'][index_entropy[0]]\n",
    "\n",
    "bestIter_silhouette = kmc_parameters['max_iter'][index_silhouette[1]]\n",
    "bestN_silhouette    = kmc_parameters['n_clusters'][index_silhouette[0]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "print(\"KMEANS\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coes√£o\n",
    "print(f\"COES√ÉO:\\nA melhor pontua√ß√£o ({maxScore_cohesion_kmeans}) foi obtida pelos par√¢metros:\\n {bestIter_cohesion} itera√ß√µes e {bestN_cohesion} centroides.\")\n",
    "\n",
    "# Separa√ß√£o\n",
    "print(f\"SEPARA√á√ÉO:\\nA melhor pontua√ß√£o ({minScore_separation_kmeans}) foi obtida pelos par√¢metros:\\n {bestIter_separation} itera√ß√µes e {bestN_separation} centroides.\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontua√ß√£o ({minScore_entropy_kmeans}) foi obtida pelos par√¢metros:\\n {bestIter_entropy} itera√ß√µes e {bestN_entropy} centroides.\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILHUETA:\\nA melhor pontua√ß√£o ({maxScore_silhouette_kmeans}) foi obtida pelos par√¢metros:\\n {bestIter_silhouette} itera√ß√µes e {bestN_silhouette} centroides.\")"
   ]
  },
  {
   "source": [
    "A partir dos gr√°ficos gerados e dos resultados exibidos, pode-se observar, no caso do KMeans, que:\n",
    "\n",
    "* Coes√£o e Separa√ß√£o apresentam comportamentos bastante semelhantes em seus gr√°ficos;\n",
    "* A Entropia apresenta comportamento tamb√©m similar √† Coes√£o e Separa√ß√£o, mas tem seu maior valor com par√¢metros diferentes daqueles da Coes√£o e Separa√ß√£o;\n",
    "* O classificador converge rapidamente, de modo que, no eixo gr√°fico correspondente ao n√∫mero de itera√ß√µes, nota-se pouca varia√ß√£o, com exce√ß√£o apenas da Silhueta;\n",
    "* Apesar das varia√ß√µes, as diferentes m√©tricas de avalia√ß√£o t√™m par√¢metros bastante similares para seus melhores valores."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## DBScan\n",
    "\n",
    "Para o classificador DBScan, os par√¢metros testados s√£o:\n",
    "* Tamanho do raio adotado (vari√°vel \"eps\")\n",
    "* N√∫mero m√≠nimo de pontos (vari√°vel \"min_samples\")\n",
    "\n",
    "Verificamos que o intervalo de valores poss√≠veis para tais par√¢metros, para que se obtenha um resultado minimamente satisfat√≥rio, √© bastante restrito. Muitas combina√ß√µes de par√¢metros faziam com que o classificador classificasse todos os pontos em uma mesma classe ou criasse um n√∫mero excessivo de classes (uma combina√ß√£o testada resultou em mais de 100 classes).\n",
    "\n",
    "Devido a isso, delimitamos as combina√ß√µes de par√¢metros poss√≠veis √†quelas nas quais o n√∫mero total de classes era igual ou menor a 8 (valor escolhido por ser o maior n√∫mero de cores b√°sicas do MatPlotLib {R,G,B,C,M,Y,B,W}, mas que √© um n√∫mero considerado grande, tendo em vista que originalmente t√≠nhamos apenas 2 classes) e nos quais o ponto central do cluster superior tivesse classe distinta do ponto central do cluster inferior (assim evitando uma classifica√ß√£o igual para todos os pontos)."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a vari√°vel banana_sup_index armazena a coordenada do ponto mais pr√≥ximo √† coordenada (0, 1), enquanto a vari√°vel banana_inf_index o faz para a coordenada (1, -0.5). Tais coordenadas foram selecionadas a partir da visualiza√ß√£o do gr√°fico do dataset, selecionando o ponto central de cada \"banana\"\n",
    "banana_sup_index = distance.cdist(X, [[.0, 1.0]]).argmin()\n",
    "banana_inf_index = distance.cdist(X, [[1.0, -0.5]]).argmin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dicion√°rio contendo os par√¢metros, onde eps varia de 0.01 a 0.15 e min_samples varia de 3 a 13\n",
    "dbs_parameters = {\n",
    "    \"eps\": [i/100 for i in range(1, 16)],\n",
    "    \"min_samples\": [i for i in range(3, 14)]\n",
    "}\n",
    "\n",
    "# a lista validate_params armazena apenas os pares de par√¢metros que atendem as condi√ß√µes descritas anteriormente\n",
    "validated_params = []\n",
    "\n",
    "# iteramos por todas as poss√≠veis combina√ß√µes de par√¢metros e testamos as condi√ß√µes\n",
    "for epsx in dbs_parameters[\"eps\"]:\n",
    "    j = 0\n",
    "    for min_sample in dbs_parameters[\"min_samples\"]:\n",
    "        dbs = DBSCAN(eps=epsx, min_samples=min_sample).fit(X)\n",
    "        dbs_labels = dbs.labels_\n",
    "\n",
    "        # a primeira condi√ß√£o verifica se a label do centro da \"banana\" superior √© diferente da label do centro da \"banana\" inferior\n",
    "        # a segunda condi√ß√£o verifica se n√£o foram geradas mais de 8 classes\n",
    "        if(dbs_labels[banana_sup_index] != dbs_labels[banana_inf_index] and len(np.unique(dbs_labels)) <= 8):\n",
    "            validated_params.append([epsx, min_sample])"
   ]
  },
  {
   "source": [
    "Os pares de par√¢metros que atendem as condi√ß√µes descritas anteriormente s√£o exibidos. Nota-se que muitas combina√ß√µes s√£o ignoradas por n√£o atenderem aos requisitos levantados previamente."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_params in validated_params:\n",
    "    plt.plot(val_params[0], val_params[1], \"k.\")\n",
    "    plt.xlabel(\"Tamanho do raio\")\n",
    "    plt.ylabel(\"N√∫mero m√≠nimo de pontos\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "   <img src=\"./images/validated_params_plot.png\" width=400/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A partir da lista de par√¢metros que atendem aos requisitos levantados, realiza-se o mesmo procedimento realizado anteriormente para extrair a pontua√ß√£o do classificador para cada combina√ß√£o de par√¢metros, conforme cada m√©trica de avalia√ß√£o."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a lista √© convertida em array do numpy\n",
    "validated_params = np.array(validated_params)\n",
    "\n",
    "unique_eps = np.unique(validated_params[:, 0]) \n",
    "unique_samples = np.unique(validated_params[:, 1]) \n",
    "\n",
    "matrix_size = ((np.shape(unique_eps)[0], np.shape(unique_samples)[0]))\n",
    "\n",
    "dbs_score_matrix_cohesion   = np.zeros(matrix_size)\n",
    "dbs_score_matrix_separation = np.zeros(matrix_size)\n",
    "dbs_score_matrix_entropy    = np.zeros(matrix_size)\n",
    "dbs_score_matrix_silhouette = np.zeros(matrix_size)\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for eps in unique_eps:\n",
    "    j = 0\n",
    "    for sample in unique_samples:\n",
    "        if [eps, sample] in validated_params.tolist():\n",
    "            dbs = DBSCAN(eps=eps, min_samples=sample, n_jobs=-1).fit(X)\n",
    "            dbs_labels = dbs.labels_ \n",
    "\n",
    "            cohesion    = cohesion_score(X, dbs_labels)\n",
    "            separation  = separation_score(X, dbs_labels)\n",
    "            entropy     = entropy_score(X, dbs_labels, label)\n",
    "            silhouette  = silhouette_score(X, dbs_labels, metric='euclidean')\n",
    "            \n",
    "            dbs_score_matrix_cohesion[i, j]     = cohesion\n",
    "            dbs_score_matrix_separation[i, j]   = separation\n",
    "            dbs_score_matrix_entropy[i, j]      = entropy\n",
    "            dbs_score_matrix_silhouette[i, j]   = silhouette\n",
    "        else: \n",
    "            # como nem todos os elementos das matrizes de pontua√ß√£o s√£o v√°lidos, os elementos inv√°lidos s√£o definidos como Infinito\n",
    "            dbs_score_matrix_cohesion[i, j]     = float(\"inf\")\n",
    "            dbs_score_matrix_separation[i, j]   = float(\"inf\")\n",
    "            dbs_score_matrix_entropy[i, j]      = float(\"inf\")\n",
    "            dbs_score_matrix_silhouette[i, j]   = float(\"inf\")\n",
    "        j+=1\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aqui, os elementos definidos como Infinito s√£o alterados para 99% do valor do menor elemento da matriz. Isso √© realizado a fim de facilitar o plot do gr√°fico tridimensional\n",
    "\n",
    "dbs_score_matrix_cohesion_ = np.where(dbs_score_matrix_cohesion == float(\"inf\"), np.min(dbs_score_matrix_cohesion)*.99, dbs_score_matrix_cohesion)\n",
    "\n",
    "dbs_score_matrix_separation_ = np.where(dbs_score_matrix_separation == float(\"inf\"), np.min(dbs_score_matrix_separation)*.99, dbs_score_matrix_separation)\n",
    "\n",
    "dbs_score_matrix_entropy_ = np.where(dbs_score_matrix_entropy == float(\"inf\"), np.min(dbs_score_matrix_entropy)*.99, dbs_score_matrix_entropy)\n",
    "\n",
    "dbs_score_matrix_silhouette_ = np.where(dbs_score_matrix_silhouette == float(\"inf\"), np.min(dbs_score_matrix_silhouette)*.99, dbs_score_matrix_silhouette)\n",
    "\n",
    "# J√° aqui, os elementos Infinito dos classificadores cuja melhor m√©trica √© a m√°xima s√£o alterados para 0, a fim de n√£o atrapalhar a extra√ß√£o dos melhores par√¢metros realizada abaixo\n",
    "dbs_score_matrix_separation = np.where(dbs_score_matrix_cohesion == float(\"inf\"), 0, dbs_score_matrix_cohesion)\n",
    "dbs_score_matrix_silhouette = np.where(dbs_score_matrix_silhouette == float(\"inf\"), 0, dbs_score_matrix_silhouette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_cohesion_, \"DBSCAN - Coes√£o\\n(menor=melhor)\", \"Tamanho do raio\", \"N√∫mero m√≠nimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_separation_, \"DBSCAN - Separa√ß√£o\\n(maior=melhor)\", \"Tamanho do raio\", \"N√∫mero m√≠nimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_entropy_, \"DBSCAN - Entropia\", \"Tamanho do raio\\n(menor=melhor)\", \"N√∫mero m√≠nimo de pontos\")\n",
    "plotScore3D(unique_samples, unique_eps, dbs_score_matrix_silhouette_, \"DBSCAN - Silhueta\", \"Tamanho do raio\\n(maior=melhor)\", \"N√∫mero m√≠nimo de pontos\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/dbscan_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/dbscan_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/dbscan_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/dbscan_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "DBSCAN\n----------------------------------------------------------------------\nCOES√ÉO:\nA melhor pontua√ß√£o (1522.3808695570162) foi obtida pelos par√¢metros:\n 0.08 tamanho de raio e 3.0 n√∫mero m√≠nimo de pontos.\n\nSEPARA√á√ÉO:\nA melhor pontua√ß√£o (1957.5406314030934) foi obtida pelos par√¢metros:\n 0.09 tamanho de raio e 13.0 n√∫mero m√≠nimo de pontos.\n\nENTROPIA:\nA melhor pontua√ß√£o (0.12317248547937495) foi obtida pelos par√¢metros:\n 0.11 tamanho de raio e 10.0 n√∫mero m√≠nimo de pontos.\n\nSILUETA:\nA melhor pontua√ß√£o (0.2516764424216868) foi obtida pelos par√¢metros:\n 0.11 tamanho de raio e 10.0 n√∫mero m√≠nimo de pontos.\n\n"
     ]
    }
   ],
   "source": [
    "# O funcionamento dessa c√©lula √© o mesmo de sua c√©lula equivalente do KMeans\n",
    "\n",
    "# Definimos o tamanho das matrizes que armazenam as pontua√ß√µes\n",
    "template_shape = np.shape(dbs_score_matrix_cohesion)\n",
    "\n",
    "# Para cada m√©todo de avalia√ß√£o, definimos a melhor pontua√ß√£o para aquele m√©todo.\n",
    "# Para Coes√£o e Silhueta, as melhores pontua√ß√µes s√£o as maiores.\n",
    "# J√° para Separa√ß√£o e Entropia, s√£o as menores.\n",
    "maxScore_cohesion_dbs   = np.min(dbs_score_matrix_cohesion)\n",
    "minScore_separation_dbs = np.max(dbs_score_matrix_separation)\n",
    "minScore_entropy_dbs    = np.min(dbs_score_matrix_entropy)\n",
    "maxScore_silhouette_dbs = np.max(dbs_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontua√ß√£o, acessamos seu √≠ndice na matriz de pontua√ß√µes para definir quais par√¢metros o originaram\n",
    "index_cohesion      = np.unravel_index(np.argmin(dbs_score_matrix_cohesion), template_shape)\n",
    "index_separation    = np.unravel_index(np.argmax(dbs_score_matrix_separation), template_shape)\n",
    "index_entropy       = np.unravel_index(np.argmin(dbs_score_matrix_entropy), template_shape)\n",
    "index_silhouette    = np.unravel_index(np.argmax(dbs_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#    DETERMINA MELHORES PAR√ÇMETROS PARA CADA M√âTRICA DE AVALIA√á√ÉO\n",
    "# -------------------------------------------------------------------\n",
    "bestEps_cohesion            = unique_eps[index_cohesion[0]]\n",
    "bestMinSamples_cohesion     = unique_samples[index_cohesion[1]]\n",
    "\n",
    "bestEps_separation          = unique_eps[index_separation[0]]\n",
    "bestMinSamples_separation   = unique_samples[index_separation[1]]\n",
    "\n",
    "bestEps_entropy             = unique_eps[index_entropy[0]]\n",
    "bestMinSamples_entropy      = unique_samples[index_entropy[1]]\n",
    "\n",
    "bestEps_silhouette          = unique_eps[index_silhouette[0]]\n",
    "bestMinSamples_silhouette   = unique_samples[index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "\n",
    "print(\"DBSCAN\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coes√£o\n",
    "print(f\"COES√ÉO:\\nA melhor pontua√ß√£o ({maxScore_cohesion_dbs}) foi obtida pelos par√¢metros:\\n {bestEps_cohesion} tamanho de raio e {bestMinSamples_cohesion} n√∫mero m√≠nimo de pontos.\\n\")\n",
    "\n",
    "# Separa√ß√£o\n",
    "print(f\"SEPARA√á√ÉO:\\nA melhor pontua√ß√£o ({minScore_separation_dbs}) foi obtida pelos par√¢metros:\\n {bestEps_separation} tamanho de raio e {bestMinSamples_separation} n√∫mero m√≠nimo de pontos.\\n\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontua√ß√£o ({minScore_entropy_dbs}) foi obtida pelos par√¢metros:\\n {bestEps_entropy} tamanho de raio e {bestMinSamples_entropy} n√∫mero m√≠nimo de pontos.\\n\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILUETA:\\nA melhor pontua√ß√£o ({maxScore_silhouette_dbs}) foi obtida pelos par√¢metros:\\n {bestEps_silhouette} tamanho de raio e {bestMinSamples_silhouette} n√∫mero m√≠nimo de pontos.\\n\")\n",
    "# -------------------------------------------------------------------"
   ]
  },
  {
   "source": [
    "A partir dos gr√°ficos gerados e dos resultados exibidos, pode-se observar, no caso do DBSCAN, que:\n",
    "\n",
    "* Coes√£o e Separa√ß√£o apresentam gr√°ficos ligeiramente semelhantes, com picos e vales em posi√ß√µes similares;\n",
    "* A Silhueta mostra, pelo seu gr√°fico, ser uma ocmbina√ß√£o da Separa√ß√£o e Silhueta, visto que seus picos e vales correspondem ora a picos e vales da Coes√£o, ora da Silhueta;\n",
    "* A Entropia apresenta um pico que representa uma regi√£o de entropia extremamente elevada, mas mant√©m valores baixos para as demais combina√ß√µes de par√¢metros;\n",
    "* N√£o houve um consenso entre as diferentes m√©tricas de quais seriam os melhores par√¢metros. Ainda que Entropia e Silhueta tenham chegado aos mesmo par√¢metros, as demais m√©tricas chegaram a valores significativamente distintos.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## AGNES"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage_dict = {\n",
    "    0: \"ward\",\n",
    "    1: \"complete\",\n",
    "    2: \"single\"\n",
    "}\n",
    "\n",
    "agc_parameters = {\n",
    "    'n_clusters': [i for i in range(2, 9)],\n",
    "    'linkage': [0, 1, 2]\n",
    "}\n",
    "\n",
    "cluster_size = np.shape(agc_parameters['n_clusters'])[0]\n",
    "linkage_size = np.shape(agc_parameters['linkage'])[0]\n",
    "\n",
    "agc_score_matrix_cohesion   = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_separation = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_entropy    = np.zeros((cluster_size, linkage_size))\n",
    "agc_score_matrix_silhouette = np.zeros((cluster_size, linkage_size))\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "for n_cluster in agc_parameters['n_clusters']:\n",
    "    j = 0\n",
    "    for linkage in agc_parameters['linkage']:\n",
    "        agc = AgglomerativeClustering(linkage=linkage_dict[linkage], n_clusters=n_cluster).fit(X)\n",
    "\n",
    "        # agc_labels = np.where(agc.labels_ == 1, 0, 1)\n",
    "        agc_labels = agc.labels_ \n",
    "\n",
    "        cohesion    = cohesion_score(X, agc_labels)\n",
    "        separation  = separation_score(X, agc_labels)\n",
    "        entropy     = entropy_score(X, agc_labels, label)\n",
    "        silhouette  = silhouette_score(X, agc_labels, metric='euclidean')\n",
    "\n",
    "        agc_score_matrix_cohesion[i, j]     = cohesion\n",
    "        agc_score_matrix_separation[i, j]   = separation\n",
    "        agc_score_matrix_entropy[i, j]      = entropy\n",
    "        agc_score_matrix_silhouette[i, j]   = silhouette\n",
    "\n",
    "        j += 1\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_cohesion, \"AGNES - Coes√£o\\n(menor=melhor)\", \"N√∫mero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_separation, \"AGNES - Separa√ß√£o\\n(maior=melhor)\", \"N√∫mero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_entropy, \"AGNES - Entropia\\n(menor=melhor)\", \"N√∫mero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")\n",
    "\n",
    "plotScore3D(agc_parameters['linkage'], agc_parameters['n_clusters'], agc_score_matrix_silhouette, \"AGNES - Silhueta\\n(maior=melhor)\", \"N√∫mero de clusters\", \"Similaridade\\n0-ward, 1-complete, 2-single\")"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/agnes_cohesion.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/agnes_separation.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/agnes_entropy.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/agnes_silhouette.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AGNES\n----------------------------------------------------------------------\nCOES√ÉO:\nA melhor pontua√ß√£o (2874.460727893919) foi obtida pelos par√¢metros:\n 2 n√∫mero de clusters e single medida de similaridade.\n\nSEPARA√á√ÉO:\nA melhor pontua√ß√£o (104.94433747931967) foi obtida pelos par√¢metros:\n 2 n√∫mero de clusters e single medida de similaridade.\n\nENTROPIA:\nA melhor pontua√ß√£o (0.005703878868730569) foi obtida pelos par√¢metros:\n 2 n√∫mero de clusters e single medida de similaridade.\n\nSILUETA:\nA melhor pontua√ß√£o (0.4651893317755256) foi obtida pelos par√¢metros:\n 2 n√∫mero de clusters e ward medida de similaridade.\n\n"
     ]
    }
   ],
   "source": [
    "# O funcionamento dessa c√©lula √© o mesmo de sua c√©lula equivalente do KMeans\n",
    "\n",
    "# Definimos o tamanho das matrizes que armazenam as pontua√ß√µes\n",
    "template_shape      = np.shape(agc_score_matrix_cohesion)\n",
    "\n",
    "# Para cada m√©todo de avalia√ß√£o, definimos a melhor pontua√ß√£o para aquele m√©todo.\n",
    "# Para Coes√£o e Silhueta, as melhores pontua√ß√µes s√£o as maiores.\n",
    "# J√° para Separa√ß√£o e Entropia, s√£o as menores.\n",
    "maxScore_cohesion_ag   = np.min(agc_score_matrix_cohesion)\n",
    "minScore_separation_ag = np.max(agc_score_matrix_separation)\n",
    "minScore_entropy_ag    = np.min(agc_score_matrix_entropy)\n",
    "maxScore_silhouette_ag = np.max(agc_score_matrix_silhouette)\n",
    "\n",
    "# Identificada a melhor pontua√ß√£o, acessamos seu √≠ndice na matriz de pontua√ß√µes para definir quais par√¢metros o originaram\n",
    "index_cohesion      = np.unravel_index(np.argmin(agc_score_matrix_cohesion), template_shape)\n",
    "index_separation    = np.unravel_index(np.argmax(agc_score_matrix_separation), template_shape)\n",
    "index_entropy       = np.unravel_index(np.argmin(agc_score_matrix_entropy), template_shape)\n",
    "index_silhouette    = np.unravel_index(np.argmax(agc_score_matrix_silhouette), template_shape)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "#    DETERMINA MELHORES PAR√ÇMETROS PARA CADA M√âTRICA DE AVALIA√á√ÉO\n",
    "# -------------------------------------------------------------------\n",
    "bestNAg_cohesion            = agc_parameters['n_clusters'][index_cohesion[0]]\n",
    "bestLinkage_cohesion     = agc_parameters['linkage'][index_cohesion[1]]\n",
    "\n",
    "bestNAg_separation          = agc_parameters['n_clusters'][index_separation[0]]\n",
    "bestLinkage_separation   = agc_parameters['linkage'][index_separation[1]]\n",
    "\n",
    "bestNAg_entropy             = agc_parameters['n_clusters'][index_entropy[0]]\n",
    "bestLinkage_entropy      = agc_parameters['linkage'][index_entropy[1]]\n",
    "\n",
    "bestNAg_silhouette          = agc_parameters['n_clusters'][index_silhouette[0]]\n",
    "bestLinkage_silhouette   = agc_parameters['linkage'][index_silhouette[1]]\n",
    "# -------------------------------------------------------------------\n",
    "# -------------------------------------------------------------------\n",
    "print(\"AGNES\")\n",
    "print(\"-\"*70)\n",
    "\n",
    "# Coes√£o\n",
    "print(f\"COES√ÉO:\\nA melhor pontua√ß√£o ({maxScore_cohesion_ag}) foi obtida pelos par√¢metros:\\n {bestNAg_cohesion} n√∫mero de clusters e {linkage_dict[bestLinkage_cohesion]} medida de similaridade.\\n\")\n",
    "\n",
    "# Separa√ß√£o\n",
    "print(f\"SEPARA√á√ÉO:\\nA melhor pontua√ß√£o ({minScore_separation_ag}) foi obtida pelos par√¢metros:\\n {bestNAg_separation} n√∫mero de clusters e {linkage_dict[bestLinkage_separation]} medida de similaridade.\\n\")\n",
    "\n",
    "# Entropia\n",
    "print(f\"ENTROPIA:\\nA melhor pontua√ß√£o ({minScore_entropy_ag}) foi obtida pelos par√¢metros:\\n {bestNAg_entropy} n√∫mero de clusters e {linkage_dict[bestLinkage_entropy]} medida de similaridade.\\n\")\n",
    "\n",
    "# Silhueta\n",
    "print(f\"SILUETA:\\nA melhor pontua√ß√£o ({maxScore_silhouette_ag}) foi obtida pelos par√¢metros:\\n {bestNAg_silhouette} n√∫mero de clusters e {linkage_dict[bestLinkage_silhouette]} medida de similaridade.\\n\")"
   ]
  },
  {
   "source": [
    "----\n",
    "\n",
    "## Compara√ß√£o dos classificadores"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "             KMeans    DBScan     Agnes\n",
       "Coes√£o     1318.316  1522.381  2874.461\n",
       "Separa√ß√£o  2556.478  1957.541   104.944\n",
       "Entropia      0.778     0.123     0.006\n",
       "Silhueta      0.475     0.252     0.465"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>KMeans</th>\n      <th>DBScan</th>\n      <th>Agnes</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>Coes√£o</th>\n      <td>1318.316</td>\n      <td>1522.381</td>\n      <td>2874.461</td>\n    </tr>\n    <tr>\n      <th>Separa√ß√£o</th>\n      <td>2556.478</td>\n      <td>1957.541</td>\n      <td>104.944</td>\n    </tr>\n    <tr>\n      <th>Entropia</th>\n      <td>0.778</td>\n      <td>0.123</td>\n      <td>0.006</td>\n    </tr>\n    <tr>\n      <th>Silhueta</th>\n      <td>0.475</td>\n      <td>0.252</td>\n      <td>0.465</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "cohesion_row = [maxScore_cohesion_kmeans,maxScore_cohesion_dbs,maxScore_cohesion_ag]\n",
    "\n",
    "separation_row = [minScore_separation_kmeans,minScore_separation_dbs,minScore_separation_ag]\n",
    "\n",
    "entropy_row = [minScore_entropy_kmeans,minScore_entropy_dbs,minScore_entropy_ag]\n",
    "\n",
    "silhouette_row = [maxScore_silhouette_kmeans,maxScore_silhouette_dbs,maxScore_silhouette_ag]\n",
    "\n",
    "storage = [\n",
    "    cohesion_row,\n",
    "    separation_row,\n",
    "    entropy_row,\n",
    "    silhouette_row\n",
    "]\n",
    "\n",
    "pd.DataFrame(storage, index=[\"Coes√£o\", \"Separa√ß√£o\", \"Entropia\", \"Silhueta\"], columns=[\"KMeans\", \"DBScan\", \"Agnes\"])"
   ]
  },
  {
   "source": [
    "De acordo com o crit√©rio de Entropia, o melhor classificador √© o Agnes, cuja classifica√ß√£o √© exibida abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "agc = AgglomerativeClustering(linkage=\"single\", n_clusters=2).fit(X)\n",
    "agc_labels = agc.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[agc_labels[i]])\n",
    "plt.title(\"AGNES\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_agnes.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "J√° de acordo com os crit√©rios de Coes√£o, Separa√ß√£o e Silhueta, o melhor classificador √© o KMeans, cuja classifica√ß√£o √© exibida abaixo."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmc = KMeans(n_clusters=2, max_iter=1).fit(X)\n",
    "kmc_labels = kmc.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[kmc_labels[i]])\n",
    "plt.title(\"KMeans\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_kmeans.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Todavia, ao observarmos as melhores classifica√ß√µes do classificador DBScan, abaixo, podemos notar resultados significativamente distintos:"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbs = DBSCAN(eps=.11, min_samples=10, n_jobs=-1).fit(X)\n",
    "dbs_labels = dbs.labels_\n",
    "\n",
    "color = [\"r.\", \"g.\", \"b.\", \"y.\", \"m.\", \"c.\", \"w.\", \"k.\"]\n",
    "for i in range(len(X)):\n",
    "    plt.plot(X[i][0], X[i][1], color[dbs_labels[i]])\n",
    "plt.title(\"DBScan\")\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "<div align=\"center\">\n",
    "    <img src=\"./images/best_dbscan.png\" width=300/>\n",
    "</div>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "---\n",
    "## Hip√≥teses Geradas\n",
    "\n",
    "### Premissa\n",
    "\n",
    "Durante todo o processo, como implementamos as fun√ß√µes (Coes√£o, Separa√ß√£o e Entropia) na m√£o, as verificamos m√∫ltiplas vezes e temos certeza que est√£o funcionando conforme as explica√ß√µes dadas em aula. Nesse sentido, conclu√≠mos que os resultados inusitados n√£o sejam ocasionados por um problema de implementa√ß√£o, mas sim por outros fatores.\n",
    "\n",
    "---\n",
    "\n",
    "### Hip√≥tese\n",
    "\n",
    "Antes de falar dos valores, a nossa hip√≥tese √© que as m√©tricas de avalia√ß√£o utilizadas n√£o s√£o as mais adequadas ao nosso dataset sem que sejam realizadas modifica√ß√µes no resultado de seus agrupamentos. Acreditamos que isso ocorra por se tratar de um dataset cujos clusters originais s√£o alongados e bastante pr√≥ximos (o que dificulta a obten√ß√£o de bons agrupamentos ao se utilizar Separa√ß√£o, Coes√£o ou Silhueta como m√©trica) e com muitos pontos de ru√≠do entre eles (o que dificulta no caso da Entropia).\n",
    "\n",
    "Segue a imagem de uma tabela que elenca os melhores resultados de cada m√©trica de avalia√ß√£o para cada met√≥do de agrupamento, informando os par√¢metros utilizados para se chegar a tal m√©trica.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_01.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "O \"problema\" aparece quando plotamos cada um dos poss√≠veis resultados presentes nessa tabela. Sendo, o \"problema\" em quest√£o, a grande diferen√ßa entre o resultado dos met√≥dos de agrupamento que supostamente deveriam ser os melhores quando comparados com o agrupamento do dataset original. Matematicamente, sabemos que o \"grau de semelhan√ßa\" entre cada um dos pontos agrupados com o seu agrupamento original √©, na realidade, a acur√°cia. Nesse sentido, para cada um dos plots dos melhores met√≥dos de agrupamento da tabela acima, mostramos no gr√°fico qual sua acur√°cia (ainda que tal m√©trica n√£o tenha sido pedida no trabalho e n√£o seja adequada para situa√ß√µes de aprendizado n√£o-supervisionado).\n",
    "\n",
    "O melhor KMeans para Coes√£o e Separa√ß√£o √© o KMeans abaixo. Como ele tem 8 clusters distintos, fizemos um teste agrupando os clusters inferiores em um s√≥, e os superiores em outro, cujo resultado √© a imagem ao lado. Ao realizar esse agrupamento ad hoc (visto que a ordena√ß√£o das classes ocorre de modo aleat√≥rio), conseguimos um resultado excelente para o met√≥do de agrupamento. Todavia, sem tal agrupamento, o resultado obtido √© bastante pobre.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_02.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_03.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "Comparando o melhor KMeans para estas duas m√©tricas com os demais met√≥dos de agrupamento para as mesmas m√©tricas, vemos que o melhor DBScan da Coes√£o (abaixo) tamb√©m realiza o agrupamento em v√°rios clusters distintos, e que, mesmo agrupando-os como feito acima, o resultado √© inferior ao do KMeans.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_04.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_05.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "J√° para o DBScan da Separa√ß√£o, o resultado √© bastante satisfat√≥rio do ponto de vista da acur√°cia. Entretanto, sua Separabilidade √© bastante inferior √† do KMeans acima (como pode ser visto na tabela).\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_06.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "Para o Agnes com melhores Coes√£o e Separabilidade, tamb√©m se chega a um n√∫mero grande de classes, conforme figura abaixo. Ao realizar o agrupamento, entretanto, chega-se √† Acur√°cia mais alta obtida at√© ent√£o.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_07.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_08.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "A partir disso, verificamos que os crit√©rios de Coes√£o e Separabilidade, por si s√≥s, n√£o s√£o boas m√©tricas para nosso dataset, visto que o melhor met√≥do de agrupamento para elas (o primeiro KMeans) apresentou um resultado bastante pobre, o qual mesmo ap√≥s agrupamento n√£o √© o melhor resultado do ponto de vista da similaridade com o dataset original. Al√©m disso, notamos que os resultados que obtiveram um grande n√∫mero de classes s√≥ apresentaram bom resultado ap√≥s o agrupamento, o qual n√£o foi necess√°rio para o DBScan com melhor Coes√£o. Consideramos isso bastante estranho, visto que, de todos estes met√≥dos de agrupamento, o DBScan da Coes√£o √© o que tem a pior Coes√£o, mas √© o qual, sem agrupamento posterior, realiza a melhor classifica√ß√£o inicial.\n",
    "\n",
    "J√° quanto √† Entropia, o melhor resultado foi do AGNES cujo resultado √© mostrado abaixo, ao lado do melhor DBScan para Entropia e melhor KMeans para Entropia.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_09.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_10.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_11.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "Percebe-se que o DBScan com maior Entropia √© um met√≥do de agrupamento muito melhor que o AGNES de maior Entropia.\n",
    "\n",
    "J√° para a m√©trica de Silhueta, o melhor resultado √© o do KMeans exibido acima. Novamente, o DBScan de maior Silhueta apresenta resultado muito melhor, enquanto o AGNES de melhor Silhueta (abaixo) apresenta resultado bastante similar ao do KMeans, apresentando acur√°cia maior, ainda que seu valor de Silhueta tenha sido menor que a do KMeans.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_12.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "A partir do exposto, n√£o t√≠nhamos certeza de como proceder, tendo em vista que os melhores met√≥dos de agrupamento para cada m√©trica (exibidos abaixo novamente para destaque) n√£o s√£o os melhores met√≥dos de agrupamento obtidos.\n",
    "\n",
    "<div align=\"center\">\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> <img src=\"./images/fig_13.png\" width=300/> </td>\n",
    "            <td> <img src=\"./images/fig_14.png\" width=300/> </td>\n",
    "        </tr>\n",
    "    </table>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"./images/fig_15.png\" width=300/>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "### Conclus√£o\n",
    "\n",
    "Acreditamos que √© v√°lida a an√°lise de que tais m√©tricas n√£o s√£o, na realidade, as melhores m√©tricas para este dataset.\n",
    "\n",
    "Al√©m disso, tudo indica que realizar o agrupamento de modo ad hoc para casos em que h√° mais de 2 clusters ou outra base n√£o √© v√°lido, visto que essas abordagens s√£o caracterizadas como aprendizagem n√£o supervisionado, de modo que utilizamos o agrupamento apenas para experimenta√ß√£o."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}